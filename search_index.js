var documenterSearchIndex = {"docs":
[{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/#Functions-and-macros","page":"API","title":"Functions and macros","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Pages = [\"internal_api.md\"]\nOrder = [:macro, :function]","category":"page"},{"location":"api/#Documentation","page":"API","title":"Documentation","text":"","category":"section"},{"location":"api/#analysis.jl","page":"API","title":"analysis.jl","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"ZeroNuFit.Analysis.retrieve_real_fit_results\nZeroNuFit.Analysis.run_analysis\nZeroNuFit.Analysis.save_outputs","category":"page"},{"location":"api/#ZeroNuFit.Analysis.retrieve_real_fit_results","page":"API","title":"ZeroNuFit.Analysis.retrieve_real_fit_results","text":"retrieve_real_fit_results(config::Dict{String,Any})\n\nFunction which handeles generating of fake data and run a signal+background model fit over it.\n\nArguments\n\nconfig::Dict{String,Any}: the fit configuration.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Analysis.run_analysis","page":"API","title":"ZeroNuFit.Analysis.run_analysis","text":"run_analysis(config::Dict{String,Any}; output_path::String, toy_idx = nothing)\n\nFunction which handeles running analysis.\n\nArguments\n\nconfig::Dict{String,Any}: the fit configuration.\noutput_path::String: the path to the output files folder.\ntoy_idx: identification index of the generated toy.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Analysis.save_outputs","page":"API","title":"ZeroNuFit.Analysis.save_outputs","text":"save_outputs(partitions, events, part_event_index, samples, posterior, nuisance_info, config, output_path, fit_ranges;priors=nothing,par_names=nothing,toy_idx=nothing)\n\nFunction to plot and save results, as well as inputs.\n\nArguments\n\npartitions: table of partitions.\nevents: list of events (=energies) in each partition.\npart_event_index: index mapping events to the partitions.\nsamples: set of generated MCMC samples.\nposterior: posterior distribution evaluated via PosteriorMeasure(likelihood, prior).\nnuisance_info: dictionary with info on the prior parameters.\nconfig: input dictionary.\noutput_path: output folder path.\nfit_ranges: dictionary of energy ranges considered for the analysis.\npriors: prior distributions.\npar_names: collection of parameter names.\ntoy_idx: identification index of the generated toy.\n\n\n\n\n\n","category":"function"},{"location":"api/#likelihood.jl","page":"API","title":"likelihood.jl","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"ZeroNuFit.Likelihood.norm_uniform\nZeroNuFit.Likelihood.norm_linear\nZeroNuFit.Likelihood.norm_exponential\nZeroNuFit.Likelihood.exp_stable\nZeroNuFit.Likelihood.gaussian_plus_lowEtail\nZeroNuFit.Likelihood.get_mu_b\nZeroNuFit.Likelihood.get_mu_s\nZeroNuFit.Likelihood.get_mu_s_b\nZeroNuFit.Likelihood.build_likelihood_zero_obs_evts\nZeroNuFit.Likelihood.build_likelihood_per_partition\nZeroNuFit.Likelihood.build_likelihood_looping_partitions\nZeroNuFit.Likelihood.get_stat_blocks\nZeroNuFit.Likelihood.run_fit_over_partitions\nZeroNuFit.Likelihood.get_signal_prior_info\nZeroNuFit.Likelihood.get_signal_bkg_priors\nZeroNuFit.Likelihood.get_bkg_pdf\nZeroNuFit.Likelihood.get_signal_pdf\nZeroNuFit.Likelihood.build_prior\nZeroNuFit.Likelihood.generate_data","category":"page"},{"location":"api/#ZeroNuFit.Likelihood.norm_uniform","page":"API","title":"ZeroNuFit.Likelihood.norm_uniform","text":"norm_uniform(x::Real,p::NamedTuple,fit_range)\n\nNormalised flat function defined by 1/norm.\n\nArguments\n\nx::Real: the x value to evaluate at.\np::NamedTuple: collection of key-value pairs where each key corresponds to a model parameter.\nfit_range: array of arrays, defining the allowed energy ranges; e.g. fit_range= [[1930,1950], [1970,1990], [2000,2050]].\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Likelihood.norm_linear","page":"API","title":"ZeroNuFit.Likelihood.norm_linear","text":"norm_linear(x::Float64,p::NamedTuple,b_name::Symbol,fit_range)\n\nNormalised linear function defined by (1+slope*(x-center)/net_width)/norm.\n\nArguments\n\nx::Real: the x value to evaluate at.\np::NamedTuple: collection of key-value pairs where each key corresponds to a model parameter.\nb_name::Symbol: name of the background index.\nfit_range: array of arrays, defining the allowed energy ranges; e.g. fit_range= [[1930,1950], [1970,1990], [2000,2050]].\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Likelihood.norm_exponential","page":"API","title":"ZeroNuFit.Likelihood.norm_exponential","text":"norm_exponential(x::Float64,p::NamedTuple,b_name::Symbol,fit_range)\n\nNormalised exponential function defined by exp_stable((x-center)*Rt)/norm.\n\nArguments\n\nx::Real: the x value to evaluate at.\np::NamedTuple: collection of key-value pairs where each key corresponds to a model parameter.\nb_name::Symbol: name of the background index.\nfit_range: array of arrays, defining the allowed energy ranges; e.g. fit_range= [[1930,1950], [1970,1990], [2000,2050]].\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Likelihood.exp_stable","page":"API","title":"ZeroNuFit.Likelihood.exp_stable","text":"exp_stable(x::Float64)\n\nExponential function, using Taylor expansion series for abs(x) < 1E-6.\n\nArguments\n\nx::Real: the x value to evaluate at.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Likelihood.gaussian_plus_lowEtail","page":"API","title":"ZeroNuFit.Likelihood.gaussian_plus_lowEtail","text":"gaussian_plus_lowEtail(evt_energy::Float64,Qbb::Float64,bias::Float64,reso::Float64,part_k::NamedTuple)\n\nSignal model based on the peak shape used for the MJD analysis. The peak shape was derived from considerations made in [S. I. Alvis et al., Phys. Rev. C 100, 025501 (2019)].\n\nArguments\n\nevt_energy::Float64: energy of the event at which we want to compute the function.\nQbb::Float64: centroid of the Gaussian.\nbias::Float64: energy bias associated to the energy event.\nreso::Float64: energy resolution associated to the energy event.\npart_k::NamedTuple: Table of specifications for a given partition k.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Likelihood.get_mu_b","page":"API","title":"ZeroNuFit.Likelihood.get_mu_b","text":"get_mu_b(deltaE, exposure, bkg_index)\n\nGet the expected number of background counts.\n\nArguments\n\ndeltaE: net width of the fit range.\nexposure: exposure (mass x time).\nbkg_index: background index value.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Likelihood.get_mu_s","page":"API","title":"ZeroNuFit.Likelihood.get_mu_s","text":"get_mu_s(exposure, eff, signal)\n\nGet the expected number of signal counts.\n\nArguments\n\nexposure: exposure (mass x time).\neff: total signal efficiency.\nsignal: number of signal counts\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Likelihood.get_mu_s_b","page":"API","title":"ZeroNuFit.Likelihood.get_mu_s_b","text":"get_mu_s_b(p::NamedTuple,part_k::NamedTuple,idx_part_with_events::Int,settings::Dict,fit_range)\n\nGet the expected number of signal and background counts.\n\nArguments\n\np::NamedTuple: collection of key-value pairs where each key corresponds to a model parameter.\npart_k::NamedTuple: Table of specifications for a given partition k.\nidx_part_with_events::Int: index of the partition with the event.\nsettings::Dict: dictionary of settings containing configuration for the likelihood calculation.\nfit_range: array of arrays, defining the allowed energy ranges; e.g. fit_range= [[1930,1950], [1970,1990], [2000,2050]].\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Likelihood.build_likelihood_zero_obs_evts","page":"API","title":"ZeroNuFit.Likelihood.build_likelihood_zero_obs_evts","text":"build_likelihood_zero_obs_evts(part_k::NamedTuple, p::NamedTuple,settings::Dict,fit_range)\n\nFunction to calculate the likelihood for a single data partition k with 0 events.\n\nArguments\n\npart_k::NamedTuple: Table of specifications for a given partition k.\np::NamedTuple: collection of key-value pairs where each key corresponds to a model parameter.\nsettings::Dict: dictionary of settings containing configuration for the likelihood calculation.\nfit_range: array of arrays, defining the allowed energy ranges; e.g. fit_range= [[1930,1950], [1970,1990], [2000,2050]].\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Likelihood.build_likelihood_per_partition","page":"API","title":"ZeroNuFit.Likelihood.build_likelihood_per_partition","text":"build_likelihood_per_partition(idx_part_with_events::Int,part_k::NamedTuple, events_k::Vector{Union{Float64}},p::NamedTuple,settings::Dict,bkg_shape::Symbol,fit_range)\n\nFunction which computes the likelihood for a single data partition k.\n\nArguments\n\nidx_part_with_events::Int: index of the partition with the event.\npart_k::NamedTuple: Table of specifications for a given partition k.\nevents_k::Vector{Union{Float64}}: vecotr of events (=energies) in the partition k.\np::NamedTuple: collection of key-value pairs where each key corresponds to a model parameter.\nsettings::Dict: dictionary of settings containing configuration for the likelihood calculation.\nbkg_shape::Symbol: Specifies the background shape; default is :uniform.\nfit_range: array of arrays, defining the allowed energy ranges; e.g. fit_range= [[1930,1950], [1970,1990], [2000,2050]].\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Likelihood.build_likelihood_looping_partitions","page":"API","title":"ZeroNuFit.Likelihood.build_likelihood_looping_partitions","text":"build_likelihood_looping_partitions(partitions::TypedTables.Table,events::Array{Vector{Float64}},part_event_index::Vector{Int},settings::Dict,sqrt_prior::Bool,s_max::Union{Float64,Nothing},fit_ranges;bkg_shape::Symbol=:uniform)\n\nFunction to build the likelihood (a DensityInterface.logfuncdensity object) for the fit by looping over partitions.\n\nArguments\n\npartitions::TypedTables.Table: table of partitions.\nevents::Array{Vector{Float64}}: list of events (=energies) in each partition.\npart_event_index::Vector{Int}: index mapping events to the partitions.\nsettings::Dict: A dictionary of settings containing configuration for the likelihood calculation.\nsqrt_prior::Bool: Whether to include the square root prior in the likelihood calculation. If False, a uniform prior is used.\ns_max::Union{Float64, Nothing}: A maximum value used for scaling the square root prior. If Nothing, no prior is applied.\nfit_ranges: The fitting ranges corresponding to the partitions.\nbkg_shape::Symbol: Specifies the background shape; default is :uniform.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Likelihood.get_stat_blocks","page":"API","title":"ZeroNuFit.Likelihood.get_stat_blocks","text":"get_stat_blocks(partitions,events::Array{Vector{Float64}},part_event_index,fit_ranges;config,bkg_only::Bool)\n\nFunction to retrieve useful pieces (prior, likelihood, posterior), also in saving values.\n\nArguments\n\npartitions: table of partitions.\nevents::Array{Vector{Float64}}: list of events (=energies) in each partition.\npart_event_index::Vector{Int}: index mapping events to the partitions.\nfit_ranges: dictionary of energy ranges considered for the analysis.\nconfig: input dictionary.\nbkg_only::Bool: True if we are using a model with background only.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Likelihood.run_fit_over_partitions","page":"API","title":"ZeroNuFit.Likelihood.run_fit_over_partitions","text":"run_fit_over_partitions(partitions,events::Array{Vector{Float64}},part_event_index::Vector{Int}, config,fit_ranges)\n\nFunction to run the fit looping over partitions.\n\nArguments\n\npartitions: table of partitions.\nevents::Array{Vector{Float64}}: list of events (=energies) in each partition.\npart_event_index::Vector{Int}: index mapping events to the partitions.\nconfig: input dictionary.\nfit_ranges: dictionary of energy ranges considered for the analysis.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Likelihood.get_signal_prior_info","page":"API","title":"ZeroNuFit.Likelihood.get_signal_prior_info","text":"get_signal_prior_info(bkg_only::Bool,config)\n\nFunction that retrieves signal prior information.\n\nArguments\n\nbkg_only::Bool: True if we are using a model with background only.\nconfig: input dictionary.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Likelihood.get_signal_bkg_priors","page":"API","title":"ZeroNuFit.Likelihood.get_signal_bkg_priors","text":"get_signal_bkg_priors(config)\n\nDefines specific priors for signal and background contributions.\n\nArguments\n\nconfig: input dictionary.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Likelihood.get_bkg_pdf","page":"API","title":"ZeroNuFit.Likelihood.get_bkg_pdf","text":"get_bkg_pdf(bkg_shape::Symbol,evt_energy::Float64,p::NamedTuple,b_name::Symbol,fit_range)\n\nReturns the background modeling function.\n\nArguments\n\nbkg_shape::Symbol: Specifies the background shape; default is :uniform.\nevt_energy::Float64: energy of the event at which we want to compute the function.\np::NamedTuple: collection of key-value pairs where each key corresponds to a model parameter.\nb_name::Symbol: name of the background index.\nfit_range: array of arrays, defining the allowed energy ranges; e.g. fit_range= [[1930,1950], [1970,1990], [2000,2050]].\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Likelihood.get_signal_pdf","page":"API","title":"ZeroNuFit.Likelihood.get_signal_pdf","text":"get_signal_pdf(evt_energy::Float64, Qbb::Float64, part_k::NamedTuple)\n\nReturns the signal modeling function.\n\nArguments\n\nevt_energy::Float64: energy of the event at which we want to compute the function.\nQbb::Float64: centroid of the Gaussian.\npart_k::NamedTuple: Table of specifications for a given partition k.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Likelihood.build_prior","page":"API","title":"ZeroNuFit.Likelihood.build_prior","text":"build_prior(partitions,part_event_index,config,settings::Dict;hierachical=false,hierachical_mode=nothing,hierachical_range=nothing,bkg_shape=:uniform,shape_pars=nothing)\n\nBuilds the priors for use in the fit.\n\nArguments\n\npartitions::Table: Table of the partition info.\npart_event_index::Vector{Int}: index for the parameters for partitions with events.\nconfig: input dictionary.\nsettings::Dict: A dictionary of settings containing configuration for the likelihood calculation.\nhierachical: True if we use a hierarchical model.\nhierachical_mode: average mode of the hierarchical model.\nhierachical_range: range of the reference distribution used to correlated the background indexes in a hierarchical model.\nbkg_shape::Symbol: Specifies the background shape; default is :uniform.\nshape_pars: background shape parameters, e.g. slope for linear or exponential background modeling.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Likelihood.generate_data","page":"API","title":"ZeroNuFit.Likelihood.generate_data","text":"generate_data(samples::BAT.DensitySampleVector,partitions::TypedTables.Table,part_event_index::Vector{Int},settings::Dict,fit_ranges;best_fit::Bool=false,seed=nothing,bkg_only=false)\n\nGenerates data from a posterior distribution. This is based on the posterior predictive distributions.  Given a model with some parameters theta_i, the posterior predictive distribution, or the distribution of data generated according to the posterior distribution of theta and the likelihood is:\n\np(yD) =int p(ytheta)p(thetaD)dtheta\n\nOr in terms of sampling we first draw samples of theta from the posterior and then generate, datasets based on the likelihood. We also give the options to fix the posterior distribution to the best fit, which is equivalent to the standard sampling methods.\n\nArguments\n\nsamples::DensitySamplesVector: samples of a past fit or a NamedTuple of best fit.\npartitions::Table: Table of the partition info.\npart_event_index::Vector{Int}: index for the parameters for partitions with events.\nsettings::Dict: A dictionary of settings containing configuration for the likelihood calculation.\nfit_ranges: dictionary of energy ranges considered for the analysis.\nbest_fit::Bool: True if you want to fix the paramaters to the best fit.\nseed::Int: random seed.\nbkg_only::Bool: True if we are using a model with background only.\n\n\n\n\n\n","category":"function"},{"location":"api/#plotting.jl","page":"API","title":"plotting.jl","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"ZeroNuFit.Plotting.plot_data\nZeroNuFit.Plotting.plot_fit_and_data\nZeroNuFit.Plotting.plot_correlation_matrix\nZeroNuFit.Plotting.plot_marginal_distr\nZeroNuFit.Plotting.plot_two_dim_posteriors\nZeroNuFit.Plotting.fit_model","category":"page"},{"location":"api/#ZeroNuFit.Plotting.plot_data","page":"API","title":"ZeroNuFit.Plotting.plot_data","text":"plot_data(hist::Histogram,name,partitions,part_event_index,pars,samples,posterior,plotflag,settings::Dict,bkg_shape::Symbol,fit_ranges)\n\nFunction to plot events in the Qbb analysis window and BAT fit results.\n\nArguments\n\nhist::Histogram: binned histogram with energy events.\nname: title of the plot.\npartitions: table of partitions.\npart_event_index: index mapping events to the partitions.\npars: free parameters in format (:B, :S, ...) \nsamples: set of generated MCMC samples.\nposterior: posterior distribution evaluated via PosteriorMeasure(likelihood, prior).\nplotflag: True if the 68% band is plotted together with the best fit result.\nsettings::Dict: dictionary of settings containing configuration for the likelihood calculation.\nbkg_shape::Symbol: Specifies the background shape; default is :uniform.\nfit_ranges: The fitting ranges corresponding to the partitions.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Plotting.plot_fit_and_data","page":"API","title":"ZeroNuFit.Plotting.plot_fit_and_data","text":"plot_fit_and_data(partitions,part_event_index,samples,posterior,pars,output,config,fit_ranges;toy_idx=nothing)\n\nRetrieves event energies and calls plot_data to plot events in the Qbb analysis window and BAT fit results. \n\nArguments\n\npartitions: table of partitions.\npart_event_index: index mapping events to the partitions.\nsamples: set of generated MCMC samples.\nposterior: posterior distribution evaluated via PosteriorMeasure(likelihood, prior).\npars: free parameters in format (:B, :S, ...) \noutput: output folder path.\nconfig: input dictionary.\nfit_ranges: The fitting ranges corresponding to the partitions.\ntoy_idx: identification index of the generated toy.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Plotting.plot_correlation_matrix","page":"API","title":"ZeroNuFit.Plotting.plot_correlation_matrix","text":"plot_correlation_matrix(samples,output;par_names=nothing,toy_idx=nothing)\n\nPlots the correlation matrixes across the free parameters. \n\nArguments\n\nsamples: set of generated MCMC samples.\noutput: output folder path.\npar_names: collection of parameter names.\ntoy_idx: identification index of the generated toy.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Plotting.plot_marginal_distr","page":"API","title":"ZeroNuFit.Plotting.plot_marginal_distr","text":"plot_marginal_distr(partitions,samples,pars,output;sqrt_prior=false,priors=nothing,par_names=nothing,plot_config=nothing,s_max=nothing,hier=false,toy_idx=nothing)\n\nFunction to plot 1D and 2D marginalized posterior distributions, and prior distributions.\n\nArguments\n\npartitions: table of partitions.\nsamples: set of generated MCMC samples.\npars: free parameters in format (:B, :S, ...) \noutput: output folder path.\nsqrt_prior: True if a 1/sqrt(signal) prior distribution was used for the signal.\npriors: True if we want to overlap priors distributions over posterior distributions.\npar_names: collection of parameter names.\nplot_config: dictionary with plotting settings.\ns_max: maximum value of the marginalized signal posterior pdf.\nhier: True if we use a hierarchical model.\ntoy_idx: identification index of the generated toy.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Plotting.plot_two_dim_posteriors","page":"API","title":"ZeroNuFit.Plotting.plot_two_dim_posteriors","text":"plot_two_dim_posteriors(samples,pars,output;par_names=nothing,toy_idx=nothing)\n\nPlots the correlation matrixes across the free parameters. \n\nArguments\n\nsamples: set of generated MCMC samples.\npars: free parameters in format (:B, :S, ...) free parameters in format (:B, :S, ...) \noutput: output folder path.\npar_names: collection of parameter names.\ntoy_idx: identification index of the generated toy.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Plotting.fit_model","page":"API","title":"ZeroNuFit.Plotting.fit_model","text":"fit_model(idx_part_with_events::Int,part_k::NamedTuple,p::NamedTuple,settings::Dict,bkg_shape::Symbol,fit_range,x::Float64)\n\nEvaòuates the total modeling function at x.\n\nArguments\n\nidx_part_with_events::Int: index of the partition with the event.\npart_k::NamedTuple: Table of specifications for a given partition k.\np::NamedTuple: collection of key-value pairs where each key corresponds to a model parameter.\nsettings::Dict: dictionary of settings containing configuration for the likelihood calculation.\nbkg_shape::Symbol: Specifies the background shape; default is :uniform.\nfit_range: array of arrays, defining the allowed energy ranges; e.g. fit_range= [[1930,1950], [1970,1990], [2000,2050]].\nx::Float64: the x value to evaluate at.\n\n\n\n\n\n","category":"function"},{"location":"api/#utils.jl","page":"API","title":"utils.jl","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"ZeroNuFit.Utils.check_key\nZeroNuFit.Utils.get_settings\nZeroNuFit.Utils.get_events\nZeroNuFit.Utils.event_is_contained\nZeroNuFit.Utils.get_partitions\nZeroNuFit.Utils.get_partitions_new\nZeroNuFit.Utils.get_partitions_events\nZeroNuFit.Utils.get_partition_event_index\nZeroNuFit.Utils.get_corr_info\nZeroNuFit.Utils.get_energy_scale_pars\nZeroNuFit.Utils.get_efficiency\nZeroNuFit.Utils.get_deltaE\nZeroNuFit.Utils.get_range\nZeroNuFit.Utils.get_bkg_info\nZeroNuFit.Utils.get_global_mode\nZeroNuFit.Utils.get_marginalized_mode\nZeroNuFit.Utils.get_par_posterior\nZeroNuFit.Utils.inverse_uniform_cdf\nZeroNuFit.Utils.generate_disjoint_uniform_samples\nZeroNuFit.Utils.save_generated_samples\nZeroNuFit.Utils.save_results_into_json","category":"page"},{"location":"api/#ZeroNuFit.Utils.check_key","page":"API","title":"ZeroNuFit.Utils.check_key","text":"check_key(config::Dict, k::String)\n\nFunction that checks the existence of a key in a dictionary. If the key is not found, the code exits here.\n\nArguments\n\nconfig::Dict: input dictionary.\nk::String: name of the key to check the existence of in config.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Utils.get_settings","page":"API","title":"ZeroNuFit.Utils.get_settings","text":"get_settings(config::Dict{String,Any})\n\nFunction that retrieves useful settings information from the input configuration dictionary.\n\nReturns a dictionary containing information on energy bias/resolution/efficiency (if fixed or not, if correlated or not) and on the type of fit (if background only or not).\n\nArguments\n\nconfig::Dict{String,Any}: input dictionary.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Utils.get_events","page":"API","title":"ZeroNuFit.Utils.get_events","text":"get_events(event_path::String,partitions)::Array{Vector{Float64}}\n\nFunction that returns an Array of Vectors filled with energy events per each partition. The code exits here if an event can't be associated to any existing partition.\n\nArguments\n\nevent_path::String: path to the input JSON file with energy events.\npartitions: Table of retrieve partitions.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Utils.event_is_contained","page":"API","title":"ZeroNuFit.Utils.event_is_contained","text":"event_is_contained(event::Float64, fit_ranges)\n\nFunction to check the containment of an energy event.\n\nReturns true if the event is contained at least in one of the selected energy ranges.\n\nArguments\n\nevent::Float64: energy event.\nfitrange: array of arrays, defining the allowed energy ranges; e.g.fitrange= [[1930,1950], [1970,1990], [2000,2050]]`\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Utils.get_partitions","page":"API","title":"ZeroNuFit.Utils.get_partitions","text":"get_partitions(config::Dict{String, Any})\n\nFunction to retrieve a Table of partitions and a dictionary of fit ranges.\n\nArguments\n\nconfig::Dict{String,Any}: input dictionary.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Utils.get_partitions_new","page":"API","title":"ZeroNuFit.Utils.get_partitions_new","text":"get_partitions_new(part_path::String)\n\nGet the partition information from a JSON file and save to a Table.\n\nReturns a Table of partitions, a dictionary of fit groups, a dictionary of fit ranges.\n\nArguments\n\npart_path::String: path to a given partition JSON file.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Utils.get_partitions_events","page":"API","title":"ZeroNuFit.Utils.get_partitions_events","text":"get_partitions_events(config::Dict{String, Any})\n\nGet partition, event, and fit range info from the configuration dictionary given in input.\n\nReturns an object descirbing if a partition has an event by assigning indexes, an array of energy events, a Table of partitions, and fit ranges.\n\nArguments\n\nconfig::Dict{String,Any}: input dictionary.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Utils.get_partition_event_index","page":"API","title":"ZeroNuFit.Utils.get_partition_event_index","text":"get_partition_event_index(events::Array{Vector{Float64}},partitions::TypedTables.Table)::Vector{Int}\n\nReturns an object describing if a partition has an event and giving them indexes. This creates a vector where\n\nV[i]=0 if partition i has no events,\nV[i]=idx if partition i has events,\n\nwhere the index counts the number of partitions with index<=i.\n\nArguments\n\nevents::Array{Vector{Float64}}: list of events (=energies) in each partition.\npartitions::TypedTables.Table: table of partitions.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Utils.get_corr_info","page":"API","title":"ZeroNuFit.Utils.get_corr_info","text":"get_corr_info(config)\n\nFunction that retrieves information about correlated background from config in input.\n\nArguments\n\nconfig: input dictionary.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Utils.get_energy_scale_pars","page":"API","title":"ZeroNuFit.Utils.get_energy_scale_pars","text":"get_energy_scale_pars(part_k::NamedTuple,p::NamedTuple,settings::Dict,idx_part_with_events)\n\nReturns the energy resolution and bias for a given partition, depending on the specified settings (e.g. if correlated or not, if fixed or not).\n\nArguments\n\np::NamedTuple: collection of key-value pairs where each key corresponds to a model parameter.\npart_k::NamedTuple: Table of specifications for a given partition k.\nsettings::Dict: a dictionary containing information on energy bias/resolution/efficiency (if fixed or not, if correlated or not) and on the type of fit (if background only or not).\nidx_part_with_events::Int: index of the partition with the event.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Utils.get_efficiency","page":"API","title":"ZeroNuFit.Utils.get_efficiency","text":"get_efficiency(p::NamedTuple,part_k::NamedTuple,idx_part_with_events::Int,settings::Dict)\n\nReturns the efficiency for a given partition, depending on the specified settings (e.g. if correlated or not, if fixed or not). If you are fitting with a background-only model, then efficiency=0.\n\nArguments\n\np::NamedTuple: collection of key-value pairs where each key corresponds to a model parameter.\npart_k::NamedTuple: Table of specifications for a given partition k.\nidx_part_with_events::Int: index of the partition with the event.\nsettings::Dict: a dictionary containing information on energy bias/resolution/efficiency (if fixed or not, if correlated or not) and on the type of fit (if background only or not).\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Utils.get_deltaE","page":"API","title":"ZeroNuFit.Utils.get_deltaE","text":"get_deltaE(fit_range)\n\nFunction that returns the net width of the fit range.\n\nArguments\n\nfit_range: array of arrays, defining the allowed energy ranges; e.g. fit_range= [[1930,1950], [1970,1990], [2000,2050]].\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Utils.get_range","page":"API","title":"ZeroNuFit.Utils.get_range","text":"get_range(fit_range)\n\nFunction that returns lower and upper edges of fit ranges.\n\nArguments\n\nfit_range: array of arrays, defining the allowed energy ranges; e.g. fit_range= [[1930,1950], [1970,1990], [2000,2050]].\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Utils.get_bkg_info","page":"API","title":"ZeroNuFit.Utils.get_bkg_info","text":"get_bkg_info(config)\n\nFunction that retrieves background shape name and parameters (if different from flat) from the input configuration dictionary.\n\nArguments\n\nconfig: input dictionary.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Utils.get_global_mode","page":"API","title":"ZeroNuFit.Utils.get_global_mode","text":"get_global_mode(samples, posterior)\n\nFunction which retrieves global mode and a refined estimate of it (using bat_findmode).\n\nArguments\n\nsamples: set of generated MCMC samples.\nposterior: posterior distribution evaluated via PosteriorMeasure(likelihood, prior).\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Utils.get_marginalized_mode","page":"API","title":"ZeroNuFit.Utils.get_marginalized_mode","text":"get_marginalized_mode(samples, par)\n\nFunction which retrieves marginalized mode as the highest bin of the posterior, using 250 bins (vs 100 bins set by default by BAT).\n\nArguments\n\nsamples: set of generated MCMC samples.\npar: name of the parameter for which we want to extract the marginalized mode.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Utils.get_par_posterior","page":"API","title":"ZeroNuFit.Utils.get_par_posterior","text":"get_par_posterior(samples, par; idx)\n\nFunction that retrieves the parameter posterior.\n\nArguments\n\nsamples: set of generated MCMC samples.\npar: name of the parameter for which we want to extract the marginalized mode.\nidx: index for multiparameters\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Utils.inverse_uniform_cdf","page":"API","title":"ZeroNuFit.Utils.inverse_uniform_cdf","text":"inverse_uniform_cdf(p, fit_range)\n\nReturns the inverse cumulative distribution function value for the given probability p.\n\nArguments\n\np: probability between 0 and 1 representing the desired quantile of the cumulative distribution.\nfit_range: array of arrays, defining the allowed energy ranges; e.g. fit_range= [[1930,1950], [1970,1990], [2000,2050]].\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Utils.generate_disjoint_uniform_samples","page":"API","title":"ZeroNuFit.Utils.generate_disjoint_uniform_samples","text":"generate_disjoint_uniform_samples(n, fit_range; seed = nothing)\n\nGenerates a list of n events uniform sampled within a specified range using the inverse CDF method.\n\nArguments\n\nn: number of events to randomly generate.\nfit_range: array of arrays, defining the allowed energy ranges; e.g. fit_range= [[1930,1950], [1970,1990], [2000,2050]].\nseed: fix to a value if you want to fix the random generator seed.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Utils.save_generated_samples","page":"API","title":"ZeroNuFit.Utils.save_generated_samples","text":"save_generated_samples(samples,output)\n\nSaves generated MCMC samples to .jld2 and .h5 files.\n\nArguments\n\nsamples: set of generated MCMC samples.\noutput: output folder path.\n\n\n\n\n\n","category":"function"},{"location":"api/#ZeroNuFit.Utils.save_results_into_json","page":"API","title":"ZeroNuFit.Utils.save_results_into_json","text":"save_results_into_json(samples,posterior,nuisance_info,config,output;par_names=nothing,toy_idx=nothing)\n\nFunction which saves results from the fit and the used input configurations.\n\nArguments\n\nsamples: set of generated MCMC samples.\nposterior: posterior distribution evaluated via PosteriorMeasure(likelihood, prior).\nnuisance_info: dictionary with info on the prior parameters.\nconfig: input dictionary.\noutput: output folder path.\npar_names: collection of parameter names.\ntoy_idx: identification index of the generated toy.\n\n\n\n\n\n","category":"function"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"Table of contents:","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"Pages = [\"likelihood.md\"]\nDepth = 3","category":"page"},{"location":"likelihood/#Likelihood-Function","page":"Likelihood implementation","title":"Likelihood Function","text":"","category":"section"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"The implemented unbinned Likelihood function reads as: ","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"beginaligned\n    mathcalL(Gamma) = prod_k bigg textrmPois(s_k+b_k) bigg prod_i_k=1^N_k frac1s_k + b_k left( b_kcdot p_rm b(E) + s_rm kcdot p_rm s(E) right)  bigg bigg\nendaligned","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"Here, the first product runs over the number of partitions k (N_rm p partitions in total) and the second over the events i in a given partition (N_rm k events in total).","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"In case no events are found in a given partition k, the above Likelihood expression simplifies into","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"beginaligned\n    mathcalL(Gamma) = prod_k textrmPois(s_k+b_k) \nendaligned","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"The terms p_rm b(E) and p_rm s(E) represent the background and signal distributions, respectively, both expressed as a function of energy E. The background distribution can be selected among different options: flat, linear or exponential. The signal distribution can be expressed in the following way","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"beginaligned\n    p_rm s(E) = fracdP(E_rm i  Q_betabeta - Delta_rm k omega_rm k)dE \nendaligned","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"for a given energy E_rm i of an event falling in the analysis window for the partition k with energy bias Delta_rm k and energy width omega_rm k. Here, we are assuming the energy biases were defined as E_rm true - E_rm cal. Thus, we correct for the energy bias by adding the calculated bias to the calibrated event energy.","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"Taking x=Q_betabeta - Delta_rm k, the signal energy distribution for each partition can be taken as a Gaussian (e.g. for GERDA/LEGEND), ","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"beginaligned\nfracdP(E  x sigma)dE = frac1sqrt2pisigma^2 times e^-fracleft(E - x right)^22 sigma ^2\nendaligned","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"Alternatively, the signal energy distribution can also be shaped as a Gaussian with a tail at low energies (e.g. for MAJORANA DEMONSTRATOR), ","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"beginaligned\nfracdP(E  x gamma)dE = frac1-fsqrt2pi(gamma sigma)^2 times e^-fracleft(E - x right)^22 (gamma sigma) ^2+fracf2gammatautimes e^ frac(gamma sigma)^22(gammatau)^2 + fracE-xgammatau  times erfc left(fracsigmasqrt2tau+ fracE-xsqrt2gammasigma right)\nendaligned","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"where f is the fraction of events in the tail (taken as fixed), tau is the scale parameter of the tail. The gamma parameter correlates the uncertainties on both sigma and tau by simultaneously scaling sigma and tau with nominal value tildegamma = 1 and uncertainty delta_gamma. Therefore, sigma and tau are taken as fixed parameters and all uncertainty is handled by gamma.","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"The background and signal counts, i.e. b_rm k and s_rm k respectively, are defined as","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"beginaligned\nb_rm k = mathcalB_rm b cdot Delta E cdot mathcalE_rm k\nendaligned","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"and","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"beginaligned\ns_rm k = fractextln2mathcalN_rm Am_rm 76 cdot (varepsilon_rm k + alpha cdot sigma_varepsilon_rm k) cdot mathcalE_rm k cdot Gamma\nendaligned","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"Notice that an extra index b was introduced to account for different background indexes mathcalB_rm b that might be shared across different partitions. In particular, for a given partition k, mathcalE_rm k is the exposure, Delta E is the net width of the fit window, varepsilon_rm k is the efficiency with uncertainty sigma_varepsilon_rm k and Gamma is the signal rate.","category":"page"},{"location":"likelihood/#Likelihood-implementation","page":"Likelihood implementation","title":"Likelihood implementation","text":"","category":"section"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"In our framework, the above Likelihood product was evaluated taking the logarithm of it.  We defined our \"log Likelihood\" (LL) as:","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"beginaligned\n    LL(Gamma)  = underbracesum_rm jsum_rm i_rm k=1^N_rm k lefttextlogleft(Pois(b_rm j+s_rm j)right) + textlogleft(b_rm j cdot p_rm b(E) + s_rm j cdot p_rm s(E) right) - textlogleft(b_rm j+s_rm j right) right_N_rm ktext events in j - underbracesum_l left(b_l+s_l right)_text0 events in l\nendaligned","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"The sum over all partitions k was separated in a sum over partitions containing an event i (j) and in a sum over partitions with no events (l).","category":"page"},{"location":"likelihood/#Free-parameter-priors","page":"Likelihood implementation","title":"Free parameter priors","text":"","category":"section"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"Different free prameters can be identified within the framework:","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"signal, Gamma\nbackground indeces, mathcalB_rm b (with b=1N)\nenergy bias at Q_betabeta, Delta = E_textrmtrue - E_textrmcal (keV)\nenergy resolution, sigma (keV)\npeak shape scale parameter, gamma (for the modified Gaussian peak shape only)\nsignal efficiencies, varepsilon","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"For the signal prior, either a uniform or a 1sqrtGamma prior can be used.","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"For the background indeces, a uniform prior can be used.","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"For nuisance parameters theta (energy biases, energy resolutions and efficiencies), Gaussian distributions centred around the true values were used","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"beginaligned\n    mathcalP(boldsymboltheta) =mathcalP(alpha) cdot  prod_rm k mathcalP_rm k(Delta)cdot mathcalP_rm k(sigma) =  e^-alpha^22 cdot prod_rm k frac1sqrt2pisigma_Delta_rm k \n      e^-fracleft(Delta_rm k - widehatDelta_rm k  right)^22 sigma_Delta_rm k ^2 cdot\n      frac1sqrt2pisigma_sigma_rm k \n      e^-fracleft(sigma_rm k - widehatsigma_rm k  right)^22 sigma_sigma_rm k ^2\nendaligned","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"Alternatively, the code allows the user to fix energy biases, energy resolutions and efficiencies at their true values, removing any prior constraint. Another feature of the framework includes the possibility to correlate energy biases and resolutions via a unique term, alpha_rm bias or alpha_rm reso, as it is done for the efficiencies in the above case. Indeed, alpha is used as a scaling parameter that fully correlated the efficiency uncertainties across all partitions, with nominal value of 0 and standard deviation of 1. Separating each partition efficiency into uncorrelated components and adding a nuisance parameter for each would require a great deal of CPU. ","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"Accounting for the different signal shape (i.e. modified Gaussian with a tail at low energies), we includeed a Gaussian prior term for the peak position offset (mu) and the peak shape scale parameter (gamma):","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"beginaligned\n      mathcalP_rm mod(boldsymboltheta) =mathcalP(alpha) cdot   prod_rm k mathcalP_rm k(mu)cdot mathcalP_rm k(sigma)=e^-alpha^22 cdotprod_rm k  frac1sqrt2pisigma_mu_rm k \n      e^-fracleft(mu_rm k - widehatmu_rm k  right)^22 sigma_mu_rm k ^2 cdot\n      frac1sqrt2pisigma_gamma_rm k \n      e^-fracleft(gamma_rm k - widehatgamma_rm k  right)^22 sigma_gamma_rm k ^2  \nendaligned","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"In the code, the product of priors was further simplified by introducing a prior term only for those partitions j for which there is at least an event.  The above products, then, can be expressed again as","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"beginaligned\n    mathcalP(boldsymboltheta) =mathcalP(alpha) cdot  prod_rm j mathcalP_rm j(Delta)cdot mathcalP_rm j(sigma) text and \n    mathcalP_rm mod(boldsymboltheta) =mathcalP(alpha) cdot  prod_rm j mathcalP_rm j(mu)cdot mathcalP_rm j(sigma)\nendaligned","category":"page"},{"location":"likelihood/#Marginalization-and-posterior-distributions","page":"Likelihood implementation","title":"Marginalization and posterior distributions","text":"","category":"section"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"The combined posterior probability density function is calculated according to Bayes’ theorem as:","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"beginaligned\n    mathcalP(Gamma boldsymbolBI boldsymbolthetaD ) propto underbracemathcalL(Gamma boldsymbolBIboldsymbolthetaD)_textLikelihood cdot underbracemathcalP(boldsymboltheta) cdot mathcalP(Gamma)cdot prod_rm b=1^N_rm b mathcalP_rm b(BI)_textprior terms\nendaligned","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"where D are our data, i.e. the energy events surviving all cuts in the fit window.  Here, we expressed the general case where a total number of N_rm b BIs are introduced. ","category":"page"},{"location":"likelihood/","page":"Likelihood implementation","title":"Likelihood implementation","text":"The marginalization is performed with the BAT toolkit via a Markov chain Monte Carlo (MCMC) numerical integration. The marginalization used the Metropolis-Hastings sampling algorithm implemented in BAT.  The number of MCMC chains and the number of steps in each MCMC can be selected by the user.","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"Table of contents:","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"Pages = [\"toys.md\"]\nDepth = 3","category":"page"},{"location":"toys/#Running-toys-for-posterior-predictive-distribution-studies","page":"Generating toys","title":"Running toys for posterior predictive distribution studies","text":"","category":"section"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"In order to check for any mis-modeling in the fits and to further understand the derived half-life limits, we performed \"sensitivity\" studies.  In a Bayesian context, the sensitivity is related to the concept of posterior predictive distributions. The prior predictive distribution is the expected distribution of data coming from a future experiment identical to that performed and repeated under the same conditions. This marginalizes the uncertainty in the model parameters, based on their prior distributions.  Alternatively, the posterior predictive distribution weights the data by the posterior obtained from the analysis. If the original data were modeled appropriately, then fake data generated under the given model should distribute similarly to the original data.","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"Considering the observed signal counts as an observable of the data, we can thus extract \"sensitivity curves\" that can be interpreted as the distribution of expected future limits derived from repeating the identical experiment. This is distinct from a frequentist sensitivity since uncertainty on nuisance parameters are marginalized over.","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"A module sensitivity.jl is present for generating toys and running sensitivity studies. The script can be run as","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"$ julia sensitivity.jl -c config_fake_data.json -i N","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"where N is an integer number corresponding to the toy index. The command can be run in an external bash script for looping over this index.","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"The input config file (config_fake_data.json) has the following entries:","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"{\n    \"path_to_fit\": \"output/fit_gerda_phIandphII_NoSignal/\",\n    \"best_fit\": false,\n    \"seed\": null\n}\n","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"where","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"\"path_to_fit\" is the path to the already performed fit over real data;\n\"best_fit\": true if we want to fix the paramaters to the best fit;\n\"seed\": null if we want a random seed when generating fake data, otherwise you can fix it to an Int value.","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"Any information about the signal being included or not in the fit of real data, was saved and retrieved from the output JSON file with results.","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"Below, we show an example of bash file used for running sensitivity studies as multiple jobs on NERSC:","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"#!/bin/bash                                                                                                                                                 \n#SBATCH -q regular                                                                                                                                       \n#SBATCH --constraint=cpu                                                                                                                                    \n#SBATCH -t 48:00:00\n#SBATCH -J sens_test                                                                                                                                         \n#SBATCH --output parallel.log                                                     \n#SBATCH --error parallel.err  \n\nmodule load parallel\nmodule load julia\nsrun=\"srun -N 1\"\nparallel=\"parallel --delay 1 -j 128\"\n\n# run parallel jobs\n$srun  $parallel \"julia sensitivity.jl -c config_fake_data.json -i {1}\" ::: {1..10000} &\n\nwait","category":"page"},{"location":"toys/#Using-already-existing-toys-to-test-alternative-models","page":"Generating toys","title":"Using already existing toys to test alternative models","text":"","category":"section"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"Another way to run the code is present if, for instance, an user wants to use toy data generated according to one model but fit them with another model. In this case, the path to the folder containing the already existing JSON files with toy data has to be provided together with the toy index:","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"julia sensitivity.jl -c config_fake_data.json -i N --path_to_toys path_to_your_toys","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"Below, an updated version of a bash file that can be used for retrieving multiple existing toy data and running sensitivity studies as multiple jobs on NERSC:","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"#!/bin/bash                                                                                                                                                 \n#SBATCH -q regular                                                                                                                                       \n#SBATCH --constraint=cpu                                                                                                                                    \n#SBATCH -t 48:00:00\n#SBATCH -J sens_test                                                                                                                                         \n#SBATCH --output parallel.log                                                     \n#SBATCH --error parallel.err             \n\n# set the directory path to toys\npath_to_toys=\"path_to_your_toys\"\nall_files=(\"$path_to_toys\"/*.json)\nfull_paths=()\nfor file in \"${all_files[@]}\"; do\n    if [[ -f \"$file\" ]]; then \n        full_paths+=(\"$file\")\n    fi\ndone\nif [ ${#full_paths[@]} -eq 0 ]; then\n    echo \"The list of existing toy data is empty! Exit here.\"\n    exit 1\nelse\n    echo \"You are going to run a fit over ${#full_paths[@]} number of already existing toys stored under $path_to_toys\"\nfi\n\n# array to hold toy_idx\ntoy_indices=()\n\n# loop over available fake JSON toys\nfor path in \"${full_paths[@]}\"; do\n    base_name=\"${path%.json}\"\n    number_str=\"${base_name##*fake_data}\"  \n    toy_idx=$((number_str))  \n\n    toy_indices+=(\"$toy_idx\") \ndone\necho \"List of toy indices: ${toy_indices[*]}\"\n\nmodule load parallel\nmodule load julia\nsrun=\"srun -N 1\"\nparallel=\"parallel --delay 1 -j 128\"\n$srun $parallel \"julia sensitivity.jl -c config/toy_9_l200_1BI_new_data_same_bkg_noS.json -i {1}\" ::: \"${toy_indices[@]}\"\n\nwait","category":"page"},{"location":".ipynb_checkpoints/api-checkpoint/#utils.jl-Documentation","page":"utils.jl Documentation","title":"utils.jl Documentation","text":"","category":"section"},{"location":".ipynb_checkpoints/api-checkpoint/","page":"utils.jl Documentation","title":"utils.jl Documentation","text":"Modules = [ZeroNuFit]","category":"page"},{"location":"installation/#First-steps","page":"First steps","title":"First steps","text":"","category":"section"},{"location":"installation/#How-to-run-the-code","page":"First steps","title":"How to run the code","text":"","category":"section"},{"location":"installation/","page":"First steps","title":"First steps","text":"Run the following command by specifying the path to the configuration file used for settings:","category":"page"},{"location":"installation/","page":"First steps","title":"First steps","text":"$ julia main.jl -c config/config.json","category":"page"},{"location":"installation/#Julia-Project-enviroments","page":"First steps","title":"Julia Project enviroments","text":"","category":"section"},{"location":"installation/","page":"First steps","title":"First steps","text":"To run the code in a virtual enviroment you can use the following. Start by entering the Julia command view by typing julia on your terminal. Once inside, enter the packagge manager (via ]), activate the environment in the current directory, and resolve (and install, if necessary) dependencies:","category":"page"},{"location":"installation/","page":"First steps","title":"First steps","text":"pkg> ] \npkg> activate .\npkg> instantiate","category":"page"},{"location":"installation/","page":"First steps","title":"First steps","text":"Now you can run the script inside this enviroment with:","category":"page"},{"location":"installation/","page":"First steps","title":"First steps","text":"$ julia main.jl --project=. -c config/config.json","category":"page"},{"location":"inputs/","page":"Partitions and events","title":"Partitions and events","text":"The fit takes in inputs two files in JSON format (for a full customization of the fit), which paths have to be specified in the config.json file.","category":"page"},{"location":"inputs/","page":"Partitions and events","title":"Partitions and events","text":"Table of contents:","category":"page"},{"location":"inputs/","page":"Partitions and events","title":"Partitions and events","text":"Pages = [\"inputs.md\"]\nDepth = 3","category":"page"},{"location":"inputs/#Partitions-file","page":"Partitions and events","title":"Partitions file","text":"","category":"section"},{"location":"inputs/","page":"Partitions and events","title":"Partitions and events","text":"The partitions file gives information on the independent spectra to be used in the fit/likelihood, this is set by the \"partitions\" key in the config file.  This provides all the information neccessary to define the fit model.","category":"page"},{"location":"inputs/","page":"Partitions and events","title":"Partitions and events","text":"The file consists of a file of independent spectra to include in the fit (for example channels or partitions).  A partition is defined uniquely by a range of time-stamps, a detector name and an experiment name. ","category":"page"},{"location":"inputs/","page":"Partitions and events","title":"Partitions and events","text":"note: Note\nIn principle the 'detector' does not need to be a single detector (e.g. C000RG1) but can be a label for any groups of detectors (e.g. COAX_dets).  This allows to make fits where all detectors are fit together.","category":"page"},{"location":"inputs/","page":"Partitions and events","title":"Partitions and events","text":"The partitions are grouped into fit_groups: these are sets of partitions which are treated with the same background/signal fit model and range. In the partitions file, the user must provide the information on the fit groups and partitions (organized by fit group). ","category":"page"},{"location":"inputs/","page":"Partitions and events","title":"Partitions and events","text":"This JSON file has a nested structure with two subdictionaries, the first with key \"fit_groups\", describing the groupings in the fit, and the second \"partitions\" giving a list of partitions for each fit group. An example is shown below.","category":"page"},{"location":"inputs/","page":"Partitions and events","title":"Partitions and events","text":"{\n\"fit_groups\":{\n                \"group_one\":{\n                            \"range\":[[1930,2099],[2109,2114],[2124,2190]],\n                            \"model\":\"uniform\",\n                            \"bkg_name\":\"low_bkg\"\n                            \"signal_name\":\"gaussian_plus_lowEtail\"\n                            }\n\n},\n\"partitions\": {\n                \"group_one\":[\n\n                            {  \n                                \"experiment\": \"LEGEND\",\n                                \"detector\": \"DET_0\",\n                                \"start_ts\": 1704950367,\n                                \"end_ts\": 1708271505,\n                                \"eff_tot\": 0.6,\n                                \"eff_tot_sigma\": 0.1,\n                                \"width\": 3,\n                                \"width_sigma\": 1,\n                                \"exposure\": 1,\n                                \"bias\": 0.2,\n                                \"bias_sigma\": 0.1\n                            }, ...\n                            ],\n                \"group_two\":...\n            },\n\n\n}\n            ","category":"page"},{"location":"inputs/","page":"Partitions and events","title":"Partitions and events","text":"They key bkg_name is used to set the name of the background parameter for this group. Note that several groups can be fitted with the same background parameter, this enables quick modification of the fit.","category":"page"},{"location":"inputs/","page":"Partitions and events","title":"Partitions and events","text":"The key \"model\":\"uniform\" is used to set the background model to uniform as default. For different background model shapes, additional information are necessary and these can be specified in the config.json (see the \"Configuration file\" documentation).","category":"page"},{"location":"inputs/","page":"Partitions and events","title":"Partitions and events","text":"warning: Warning\nThe background shape is set to global for all partitions, differently from the signal shape (see below) that can be specified differently for each fit group.","category":"page"},{"location":"inputs/","page":"Partitions and events","title":"Partitions and events","text":"Notice it is possible to specify the signal shape for each fit group.  The available options at the moment are \"signal_name\":\"gaussian_plus_lowEtail\" or \"signal_name\":\"gaussian\" (default). If the key is omitted, the default Gaussian signal shape will be adopted. Notice that if you want to use the \"signal_name\":\"gaussian_plus_lowEtail\" option (eg for MAJORANA DEMONSTRATOR data), you need to provide additional input signal shape parameters (frac, sigma, tau). ","category":"page"},{"location":"inputs/","page":"Partitions and events","title":"Partitions and events","text":"note: Note\nMAJORANA DEMONSTRATOR (MJD) input data are taken from \"I. J. Arnquist et al., Final Result of the Majorana Demonstrator’s Search for Neutrinoless Double- β Decay in Ge 76, PRL 130, 062501 (2023)\".  Here, you can find the input data under the supplemental materials: supp_analysis_parameters.txt and supp_event_list.txt.","category":"page"},{"location":"inputs/","page":"Partitions and events","title":"Partitions and events","text":"warning: Warning\nNotice that the width parameter assumes different meanings depending on the chosen signal shape:if \"signal_name\":\"gaussian_plus_lowEtail\", width is the fractional uncertainty on the FWHM of the peak at 2039 keV (it rescales the energy resolution of the peak)\nif \"signal_name\":\"gaussian\", width is the energy resolution expressed in standard deviations (NOT in FWHM)","category":"page"},{"location":"inputs/#Events-file","page":"Partitions and events","title":"Events file","text":"","category":"section"},{"location":"inputs/","page":"Partitions and events","title":"Partitions and events","text":"In addition, it is neccessary to provide an 'event' file describing the events observed in the data, the path to this file is specified by the 'events' key in the config. Again this is a JSON file consisting of a list of observed events of the form.","category":"page"},{"location":"inputs/","page":"Partitions and events","title":"Partitions and events","text":"    {       \"experiment\":\"LEGEND\",\n            \"energy\": 2069.420,\n            \"timestamp\": 1755109448,\n            \"detector\": \"DET_0\"\n        },","category":"page"},{"location":"inputs/","page":"Partitions and events","title":"Partitions and events","text":"The timestamp and detector are used to extract which partition this event corresponds to. To convert to this format from the standard GERDA and LEGEND files, there are tools available in https://github.com/tdixon97/legend-0vbb-config.","category":"page"},{"location":"inputs/","page":"Partitions and events","title":"Partitions and events","text":"It is possible to supply a list of partition and event files in this case the list of fit groups and events are concatenated.","category":"page"},{"location":"inputs/","page":"Partitions and events","title":"Partitions and events","text":"warning: Warning\nIf multiple files are provided fit_group must still be unique.","category":"page"},{"location":"#ZeroNuFit.jl-Documentation","page":"Home","title":"ZeroNuFit.jl Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Welcome to the documentation for ZeroNuFit.jl.","category":"page"},{"location":"#Introduction","page":"Home","title":"Introduction","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"ZeroNuFit.jl is a Julia package for running an extended unbinned fit of a Gaussian signal over a background for the neutrinoless double-beta decay (0nubetabeta) analysis. The tool was developed for the LEGEND experiment but it can be easily extended to data collected by any other 0nubetabeta experiment or to any other physical processes that can be modelled in a similar way.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The package uses the BAT.jl tool box  for Bayesian inference (see O. Schulz, F. Beaujean, A. Caldwell, C. Grunwald, V. Hafych, K. Kröninger et al., “Bat.jl: A julia-based tool for bayesian inference”, SN Computer Science 2 (2021) 210).","category":"page"},{"location":"#Table-of-contents","page":"Home","title":"Table of contents","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = [\n    \"likelihood.md\",\n    \"installation.md\",\n    \"config.md\",\n    \"inputs.md\",\n    \"toys.md\",\n    \"tutorial.md\",\n]\nDepth = 1","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The aim of this tutorial consists in building proper config JSON files in order to run a neutrinoless double-beta decay analysis over GERDA and MAJORANA DEMONSTRATO (MJD) published data. Additional info on the meaning of input parameters can be found under the \"Configuration file\" section, and for input files under the \"Partitions and events\" section.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Table of contents:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Pages = [\"tutorial.md\"]\nDepth = 3","category":"page"},{"location":"tutorial/#GERDA-Phase-I:-SB-fit","page":"Tutorial","title":"GERDA Phase I: S+B fit","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Let's start by fitting data acquired by the GERDA experiment during its Phase I and let's fit them with a signal+background model.","category":"page"},{"location":"tutorial/#Input-files","page":"Tutorial","title":"Input files","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"First of all, we have to populate partitions and events JSON input files. These dictionaries can be built manually by each user, but some reference files are already present for GERDA/LEGEND/MJD experiments at a private location (ask Toby Dixon for access to the repository). Some of these files were also copied in the inputs/ folder for already published material. The following files can be used for this tutorial:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"GERDA Phase I Events -> \"inputs/events_gerda_pI.json\"\nGERDA Phase I Partitions -> \"inputs/partitions_gerda_pI.json\"","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Notice that in \"inputs/partitions_gerda_pI.json\" we already specify in which range we want to fit data (here it is set common to all fit groups, i.e. [1930,2099] U [2109,2114] U [2124,2190] keV) and how we want to group different detectors. In particular, 4 fit groups are specified, with names ph1_golden, ph1_silver, phI_bege and phI_extra. For each group, we will have a separate background index (BI): mathcalB_phI-golden, mathcalB_phI-silver, mathcalB_phI-bege, mathcalB_phI-extra. In case you want one BI only for all phase I events, mathcalB_phI-all, then you have to modify the partitions input file to account for that.","category":"page"},{"location":"tutorial/#Fit-configuration","page":"Tutorial","title":"Fit configuration","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Let's fit GERDA Phase I events with a simple signal+background=S+B model (\"bkg_only\": false) where the signal is modelled with a Gaussian function (default option).","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The signal prior is taken as uniform (\"signal\": {\"prior\": \"uniform\", ...}) in 010^-24 yr^-1. Notice that for the signal the values are expressed in terms of 10^-27yr^-1 (that is why \"signal\": {\"upper_bound\": 1000, ...}). The BI prior is taken as uniform (\"bkg\": {\"prior\": \"uniform\", ...}) in 001 counts/keV/kg/yr.  Signal and background are always defined as positive, i.e. the lower bound is set to 0 by default.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"We assume the 4 BIs are not correlated (\"bkg\": {\"correlated\": {\"mode\": \"none\", \"range\": \"none\"}}). If they are, change the entry into \"bkg\": {\"correlated\": {\"mode\": x, \"range\": [...,...]}} where x={\"lognormal\", \"normal\"}. These are the only hierarchical models present at the moment. More documentation on this topic can be found in \"A. Gelman, J.B. Carlin, H.S. Stern, D.B. Dunson, A. Vehtari and D.B. Rubin, “Bayesian Data Analysis (3rd ed.)”, Chapman & Hall (2013)\".","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"As regards the nuisance parameters, we can leave free the energy biases and energy widths by not fixing them to their best value (\"nuisance\": {\"energy_scale\": {\"fixed\": false, ...}, ...}), but constraining them via a Gaussian prior. An additional option for treating all energy biases or widths together via one common parameter, i.e. alpha_Delta or alpha_omega, can be enabled/disabled. For the moment, we leave this out and we treat nuisance parameters individually (\"nuisance\": {\"energy_scale\": {\"correlated\": false, ...}, ...}).","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"As regards the efficiencies, we don't fix the values to their best value (\"nuisance\": {\"efficiency\": {\"fixed\": false, ...}, ...}), but we correlated them via a global parameter alpha_varepsilon (\"nuisance\": {\"efficiency\": {\"correlated\": true, ...}, ...}).","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"All these fit settings can therefore be grouped in the following config JSON file with name config_gerda_phI.json: ","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"{\n    \"debug\":false,\n    \"events\":    [\"inputs/events_gerda_pI.json\"],\n    \"partitions\":[\"inputs/partitions_gerda_pI.json\"],\n    \"output_path\": \"output/fit_gerda_phI/\",\n    \"overwrite\": true,\n    \"light_output\": false,\n    \"bat_fit\": {\"nsteps\": 1e6, \"nchains\": 6},\n    \"plot\": {\"fit_and_data\": false, \"bandfit_and_data\": false, \"scheme\":\"green\", \"alpha\": 0.3},\n    \"bkg_only\": false,\n    \"signal\": {\"upper_bound\": 1000, \"prior\": \"uniform\"},\n    \"bkg\": {\"upper_bound\": 0.1, \"prior\": \"uniform\", \"correlated\": {\"mode\": \"none\", \"range\": \"none\"}},\n    \"nuisance\": { \n        \"energy_scale\" : {\n            \"correlated\": false,\n            \"fixed\": false\n        },\n        \"efficiency\" : {\n            \"correlated\": true,\n            \"fixed\": false\n        }\n    }\n}","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"You can now run this fit by running","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"$ julia main.jl -c config_gerda_phI.json","category":"page"},{"location":"tutorial/#GERDA-Phase-I-and-II:-SB-fit","page":"Tutorial","title":"GERDA Phase I and II: S+B fit","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Let's add data acquired by the GERDA experiment during its Phase II and let's fit them with a S+B model, leaving previous settings invariate.","category":"page"},{"location":"tutorial/#Input-files-2","page":"Tutorial","title":"Input files","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"In the partitions file, we group detectors from Phase II in one fit group only (i.e. all_phase_II) such that they all share one BI, i.e. mathcalB_phII-all.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"GERDA Phase II events -> \"inputs/events_gerda_pII.json\"\nGERDA Phase II partitions -> \"inputs/partitions_gerda_pII.json\"","category":"page"},{"location":"tutorial/#Fit-configuration-2","page":"Tutorial","title":"Fit configuration","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Combined fits of different phases of one experiment (or, from a more general point of view, combined fits of different experiments) can be achieved by introducing new events and partitions files to the config JSON file.  Let's create the following config JSON file with name config_gerda_phIandphII.json: ","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"{\n    ...,\n    \"events\":    [\"inputs/events_gerda_pI.json\", \"inputs/events_gerda_pII.json\"],\n    \"partitions\":[\"inputs/partitions_gerda_pI.json\", \"inputs/partitions_gerda_pII.json\"],\n    \"output_path\": \"output/fit_gerda_phIandphII/\",\n    ...\n}","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"All the rest can be left unchanged and you can now run the GERDA Phase I+II combined fit by running","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"$ julia main.jl -c config_gerda_phIandphII.json","category":"page"},{"location":"tutorial/#GERDA-Phase-I-and-II:-SB-fit,-non-flat-background","page":"Tutorial","title":"GERDA Phase I and II: S+B fit, non flat background","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The background is assumed flat by default, but how can we include a potential different shape? A linear or exponential background shape were implemented as well, and one of these shapes can be specified under the \"bkg\" key. Let's create the following config JSON file with name config_gerda_phIandphII_linearB.json: ","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"{\n    ...,\n    \"events\":    [\"inputs/events_gerda_pI.json\", \"inputs/events_gerda_pII.json\"],\n    \"partitions\":[\"inputs/partitions_gerda_pI.json\", \"inputs/partitions_gerda_pII.json\"],\n    \"output_path\": \"output/fit_gerda_phIandphII_linearB/\",\n    \"bkg\": {\n        \"upper_bound\": 0.1, \n        \"prior\": \"uniform\",\n        \"correlated\": {\"mode\": \"none\", \"range\": \"none\"},\n        \"shape\":{\n            \"name\":\"linear\",\n            \"pars\":{\"slope\":[-1,3]}\n        }\n    },\n    ...\n}","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"or config_gerda_phIandphII_expoB.json:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"{\n    ...,\n    \"events\":    [\"inputs/events_gerda_pI.json\", \"inputs/events_gerda_pII.json\"],\n    \"partitions\":[\"inputs/partitions_gerda_pI.json\", \"inputs/partitions_gerda_pII.json\"],\n    \"output_path\": \"output/fit_gerda_phIandphII_expoB/\",\n    \"bkg\": {\n        \"upper_bound\": 0.1, \n        \"prior\": \"uniform\",\n        \"correlated\": {\"mode\": \"none\", \"range\": \"none\"},\n        \"shape\":{\n            \"name\":\"exponential\",\n            \"pars\":{\"slope\":[-10,10]}\n        }\n    },\n    ...\n}","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"You can now run this fit by running","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"$ julia main.jl -c config_gerda_phIandphII_linearB.json","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"if you want to shape the background with a linear function, or ","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"$ julia main.jl -c config_gerda_phIandphII_expoB.json","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"if you want to shape the background with an exponential function.","category":"page"},{"location":"tutorial/#GERDA-Phase-I-and-II:-B-only-fit","page":"Tutorial","title":"GERDA Phase I and II: B only fit","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Sometimes it is required to fit under the mathcalS=0 (no signal) assumption. This might be helpful when performing sensitivity studies in the context of 0nubetabeta decay analyses. This can be achieved by setting \"bkg_only\": true in our config JSON file that we now call config_gerda_phIandphII_NoSignal.json:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"{\n    ...,\n    \"events\":    [\"inputs/events_gerda_pI.json\", \"inputs/events_gerda_pII.json\"],\n    \"partitions\":[\"inputs/partitions_gerda_pI.json\", \"inputs/partitions_gerda_pII.json\"],\n    \"output_path\": \"output/fit_gerda_phIandphII_NoSignal/\",\n    \"bkg_only\": true,\n    ...\n}","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"You can now run this fit by running","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"$ julia main.jl -c config_gerda_phIandphII_NoSignal.json","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Additional details on the type of available sensitivity studies (e.g. how to generate fake spectra and fit them) can be found in the \"Generating toys\" section.","category":"page"},{"location":"tutorial/#GERDA-MJD:-different-S-shapes","page":"Tutorial","title":"GERDA + MJD: different S shapes","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"As explained in \"I. J. Arnquist et al., Final Result of the Majorana Demonstrator’s Search for Neutrinoless Double- β Decay in Ge 76, PRL 130, 062501 (2023)\", MJD used a modified Gaussian signal peak shape. The code can take care of this difference once you specify the type of signal shape one wants to use in the partitions file. Use \"signal_name\": \"gaussian_plus_lowEtail\" for MJD, and \"signal_name\": \"gaussian\" (or don't enter any key - this is the default option) for GERDA partitions. Below we report an example of how the MJD partitions JSON file should look like for changing the Gaussian signal function into a modified one. Notice that for MJD we can also specify a different fit range (that now includes an additional window in 2209.1-2350.0 keV) compared to the one used by GERDA.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"    {\n        \"fit_groups\": {\n            \"mjd-DS0\": {\n                \"range\": [[1950.0, 2098.511], [2108.511, 2113.513], [2123.513, 2199.1], [2209.1, 2350.0]],\n                \"model\": \"uniform\",\n                \"bkg_name\": \"B_mjd-DS0\",\n                \"signal_name\": \"gaussian_plus_lowEtail\"\n            }\n        },\n        \"partitions\": {\n            \"mjd-DS0\": [...]\n        }\n    }","category":"page"},{"location":"config/","page":"Configuration file","title":"Configuration file","text":"Table of contents:","category":"page"},{"location":"config/","page":"Configuration file","title":"Configuration file","text":"Pages = [\"config.md\"]\nDepth = 3","category":"page"},{"location":"config/#Building-the-configuration-file","page":"Configuration file","title":"Building the configuration file","text":"","category":"section"},{"location":"config/","page":"Configuration file","title":"Configuration file","text":"Before running the code, set the input config.json file with following entries:","category":"page"},{"location":"config/","page":"Configuration file","title":"Configuration file","text":"{\n    \"debug\":false,\n    \"partitions\":[\"config/partitions_gerda_new.json\",\"config/partitions_l200.json\",\"config/partitions_mjd_new.json\"],\n    \"events\":    [\"config/events_gerda.json\",\"config/events_l200.json\",\"config/events_mjd_new_part.json\"],\n    \"output_path\": \"output/fit_mjd_l200_gerda_v2/\",\n    \"overwrite\":true,\n    \"bat_fit\": {\"nchains\": 6, \"nsteps\": 1e6},\n    \"plot\": {\n            \"fit_and_data\": false,\n            \"bandfit_and_data\": false,\n            \"scheme\":\"red\",\n            \"alpha\":0.3\n        },\n    \"bkg_only\": false,\n    \"signal\": {\"upper_bound\":1000, \"prior\": \"uniform\"},\n    \"bkg\": {\"upper_bound\":0.1,\n             \"prior\": \"uniform\",\n             \"correlated\": {\"mode\": \"none\", \"range\": \"none\"}\n             },\n    ...\n}","category":"page"},{"location":"config/","page":"Configuration file","title":"Configuration file","text":"where","category":"page"},{"location":"config/","page":"Configuration file","title":"Configuration file","text":"\"debug\": true if you want to display debug output on terminal;\n\"partitions\": list of partitions JSON inputs; it takes one entry per experiment;\n\"events\": list of events JSON inputs; it takes one entry per experiment;\n\"output_path\": path where to store outputs (logs, plots, mcmc results);\n\"overwrite\": true if you want to overwrite a previous fit with same output_path; if set to false but no fits were previously performed (ie there are no outputs to overwrite), the code will save the output of this fit;\n\"bat_fit\": settings for the BAT fit, \"nchains\" numer of MCMC chains to run, \"nsteps\" number of steps for each MCMC chain;\n\"plot\": settings for plotting; \"fit_and_data\": true plots fit line over data (and CI bands if \"bandfit_and_data\": true); \"scheme\":\"red\" and \"alpha\":0.3 are used for customizing output appearances;\n\"bkg_only\": true if we fit assuming no signal (S=0), false otherwise;\n\"signal\": select \"upper_bound\" for the prior and the \"prior\" shape (uniform, sqrt, ...);\n\"bkg\": select \"upper_bound\" for the prior and the \"prior\" shape (uniform, ...) there are several optional keys with details given below, if these are not provided the fit defaults to a flat background without correlations.","category":"page"},{"location":"config/","page":"Configuration file","title":"Configuration file","text":"Moreover, the config requires the following block for nuisance parameters, ie energy scale (=energy bias and resolution) and efficiency:","category":"page"},{"location":"config/","page":"Configuration file","title":"Configuration file","text":"    {\n    ...\n    \"nuisance\": { \n         \"energy_bias\": {\n            \"fixed\": false,\n            \"correlated\": false\n         },\n         \"energy_res\": {\n            \"fixed\": false,\n            \"correlated\": false\n         },\n         \"efficiency\" : {\n            \"correlated\": true,\n            \"fixed\": false\n            }\n    }","category":"page"},{"location":"config/","page":"Configuration file","title":"Configuration file","text":"In particular, you can set \"correlated\": true if you want to use one variable to correlate the nuisance parameters (eg to speed up the computation times), and \"fixed\": false if you want to include a prior for nuisance parameters (otherwise these parameters they will be fixed to their partition value and not constrained).","category":"page"},{"location":"config/","page":"Configuration file","title":"Configuration file","text":"If a variable is correlated (either energy_bias or energy_res or efficiency), the code will search for a field in the fit_groups block of the partitions JSON file to use a correlated variable per each fit group.  In particular, the field has to be specified as:","category":"page"},{"location":"config/","page":"Configuration file","title":"Configuration file","text":"\"energy_bias_group_name\": \"...\"\n\"energy_res_group_name\": \"...\"\n\"efficiency_group_name\": \"...\"","category":"page"},{"location":"config/","page":"Configuration file","title":"Configuration file","text":"Parameters are then added to the model called αr_\\$name (for resolution), αe_\\$name for efficiency and αb_\\$name for bias.","category":"page"},{"location":"config/","page":"Configuration file","title":"Configuration file","text":"warning: Warning\nThe alpha parameter names default to _all, if you want one different per experiment this must be explicitly specified in the fit groups entry","category":"page"},{"location":"config/#Background-shape-and-correlation","page":"Configuration file","title":"Background shape and correlation","text":"","category":"section"},{"location":"config/","page":"Configuration file","title":"Configuration file","text":"There are several options to control the background in more detail. These can be added to the \"bkg\" section of the config: In particular:","category":"page"},{"location":"config/","page":"Configuration file","title":"Configuration file","text":"\"correlated\" adds a hierarchical (correlated) background to the model, this key should have a dictionary giving details on the prior shape and ranges. The three options for the mode are: none (default), lognormal or normal. The range entry is associated to the range used for the uniform prior on the \\$sigma_B parameter. For example:","category":"page"},{"location":"config/","page":"Configuration file","title":"Configuration file","text":"\"correlated\": {\"mode\":\"lognormal\",\"range\":[0,1]}","category":"page"},{"location":"config/","page":"Configuration file","title":"Configuration file","text":"\"shape\" changes the shape of the background from uniform. The user should provide a dictionary giving details on the shape. For example:","category":"page"},{"location":"config/","page":"Configuration file","title":"Configuration file","text":"\"shape\": {\n            \"name\":\"exponential\",\n            \"pars\":{\"slope\":[-10,10]}\n        },","category":"page"},{"location":"config/","page":"Configuration file","title":"Configuration file","text":"The \"pars\" subdictionary describes the range of the priors on the parameters of the model, currently implemented shapes are \"uniform\", \"linear\" and \"exponential\". These names correspond to functions in fitting.jl and logical conditions in get_bkg_pdf in likelihood.jl.","category":"page"},{"location":"config/","page":"Configuration file","title":"Configuration file","text":"This will add parameters ${bkg_name}_slope or similar to the model (and then call them). This names therefore must correspond to the names in the functions in fitting.jl. To add a new shape simply define a new method in fitting.jl and a new logical condition in get_bkg_pdf in likelihood.jl.","category":"page"},{"location":"config/","page":"Configuration file","title":"Configuration file","text":"note: Note\nIf these keys are not provided the model defaults to a uniform uncorrelated background.","category":"page"},{"location":"config/#Signal-shape","page":"Configuration file","title":"Signal shape","text":"","category":"section"},{"location":"config/","page":"Configuration file","title":"Configuration file","text":"The signal shape can be specified in the partition JSON file in order to have a different signal shape for different partitions. An example is given by the combined fit of GERDA/LEGEND and MAJORANA DEMONSTRATOR (MJD) partitions where for the first one we want to model the signal with a simple gaussian function while we want to model data from MJD accounting for an additional tail at the low-energy side of the gaussian. See the \"Partitions and events\" documentation.","category":"page"}]
}
