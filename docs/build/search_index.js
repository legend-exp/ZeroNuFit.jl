var documenterSearchIndex = {"docs":
[{"location":".ipynb_checkpoints/toys-checkpoint/#Generating-toys","page":"Generating toys","title":"Generating toys","text":"","category":"section"},{"location":".ipynb_checkpoints/toys-checkpoint/","page":"Generating toys","title":"Generating toys","text":"Another module is present for generating toys and running sensitivity studies. This can be run as","category":"page"},{"location":".ipynb_checkpoints/toys-checkpoint/","page":"Generating toys","title":"Generating toys","text":"julia sensitivity.jl -c config_fake_data.json -i N","category":"page"},{"location":".ipynb_checkpoints/toys-checkpoint/","page":"Generating toys","title":"Generating toys","text":"where N is an integer number corresponding to the toy index. The command can be run in an external bash script for looping over this index.","category":"page"},{"location":".ipynb_checkpoints/toys-checkpoint/","page":"Generating toys","title":"Generating toys","text":"The input config file (config_fake_data.json) has the following entries:","category":"page"},{"location":".ipynb_checkpoints/toys-checkpoint/","page":"Generating toys","title":"Generating toys","text":"{\n    \"path_to_fit\": \"output/fit_alpha_high_stat_true_TOBY4_v4/\",\n    \"best_fit\": false,\n    \"seed\": null\n}\n","category":"page"},{"location":".ipynb_checkpoints/toys-checkpoint/","page":"Generating toys","title":"Generating toys","text":"where","category":"page"},{"location":".ipynb_checkpoints/toys-checkpoint/","page":"Generating toys","title":"Generating toys","text":"\"path_to_fit\" is the path to the already performed fit over real data;\n\"best_fit\": true if we want to fix the paramaters to the best fit;\n\"seed\": null if we want a random seed when generating fake data, otherwise you can fix it to an Int value.","category":"page"},{"location":".ipynb_checkpoints/toys-checkpoint/","page":"Generating toys","title":"Generating toys","text":"Any information about the signal being included or not in the fit of real data, was saved and retrieved from the output JSON file with results.","category":"page"},{"location":".ipynb_checkpoints/toys-checkpoint/","page":"Generating toys","title":"Generating toys","text":"Below, we show an example of bash file used for running sensitivity studies as multiple jobs on NERSC:","category":"page"},{"location":".ipynb_checkpoints/toys-checkpoint/","page":"Generating toys","title":"Generating toys","text":"#!/bin/bash                                                                                                                                                 \n#SBATCH -q regular                                                                                                                                       \n#SBATCH --constraint=cpu                                                                                                                                    \n#SBATCH -t 48:00:00\n#SBATCH -J sens_test                                                                                                                                         \n\n#SBATCH --mail-user=<your_email>\n#SBATCH --mail-type=ALL                                                                                                                                     \n#SBATCH --output output_path/parallel.log                                                     \n#SBATCH --error output_path/parallel.err  \n\n#SBATCH  --image=legendexp/legend-base:latest               \n\nmodule load parallel\nmodule load julia\nsrun=\"srun -N 1\"\nparallel=\"parallel --delay 1 -j 128\"\n\n# run parallel jobs\n$srun  $parallel \"julia sensitivity.jl -c config_fake_data.json -i {1}\" ::: {1..10000} &\n\nwait","category":"page"},{"location":".ipynb_checkpoints/installation-checkpoint/#First-steps","page":"First steps","title":"First steps","text":"","category":"section"},{"location":".ipynb_checkpoints/installation-checkpoint/#How-to-run-the-code","page":"First steps","title":"How to run the code","text":"","category":"section"},{"location":".ipynb_checkpoints/installation-checkpoint/","page":"First steps","title":"First steps","text":"Run the following command by specifying the path to the configuration file used for settings:","category":"page"},{"location":".ipynb_checkpoints/installation-checkpoint/","page":"First steps","title":"First steps","text":"julia main.jl -c config/config.json","category":"page"},{"location":".ipynb_checkpoints/installation-checkpoint/#Julia-Project-enviroments","page":"First steps","title":"Julia Project enviroments","text":"","category":"section"},{"location":".ipynb_checkpoints/installation-checkpoint/","page":"First steps","title":"First steps","text":"To run the code in a virtual enviroment you can use the following.","category":"page"},{"location":".ipynb_checkpoints/installation-checkpoint/","page":"First steps","title":"First steps","text":"julia\n] \nactivate .\ninstantiate\n","category":"page"},{"location":".ipynb_checkpoints/installation-checkpoint/","page":"First steps","title":"First steps","text":"Now you can run the script inside this enviroment with:","category":"page"},{"location":".ipynb_checkpoints/installation-checkpoint/","page":"First steps","title":"First steps","text":"julia main.jl --project=. -c config/config.json","category":"page"},{"location":".ipynb_checkpoints/installation-checkpoint/","page":"First steps","title":"First steps","text":"[!NOTE]  The tool was developed for the LEGEND experiment. People from the LEGEND Collaborations can alternatively run the code within a LEGEND container with julia installed, see this tutorial for more details.","category":"page"},{"location":".ipynb_checkpoints/installation-checkpoint/","page":"First steps","title":"First steps","text":"","category":"page"},{"location":"toys/#Generating-toys","page":"Generating toys","title":"Generating toys","text":"","category":"section"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"Another module is present for generating toys and running sensitivity studies. This can be run as","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"julia sensitivity.jl -c config_fake_data.json -i N","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"where N is an integer number corresponding to the toy index. The command can be run in an external bash script for looping over this index.","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"The input config file (config_fake_data.json) has the following entries:","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"{\n    \"path_to_fit\": \"output/fit_alpha_high_stat_true_TOBY4_v4/\",\n    \"best_fit\": false,\n    \"seed\": null\n}\n","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"where","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"\"path_to_fit\" is the path to the already performed fit over real data;\n\"best_fit\": true if we want to fix the paramaters to the best fit;\n\"seed\": null if we want a random seed when generating fake data, otherwise you can fix it to an Int value.","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"Any information about the signal being included or not in the fit of real data, was saved and retrieved from the output JSON file with results.","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"Below, we show an example of bash file used for running sensitivity studies as multiple jobs on NERSC:","category":"page"},{"location":"toys/","page":"Generating toys","title":"Generating toys","text":"#!/bin/bash                                                                                                                                                 \n#SBATCH -q regular                                                                                                                                       \n#SBATCH --constraint=cpu                                                                                                                                    \n#SBATCH -t 48:00:00\n#SBATCH -J sens_test                                                                                                                                         \n\n#SBATCH --mail-user=<your_email>\n#SBATCH --mail-type=ALL                                                                                                                                     \n#SBATCH --output output_path/parallel.log                                                     \n#SBATCH --error output_path/parallel.err  \n\n#SBATCH  --image=legendexp/legend-base:latest               \n\nmodule load parallel\nmodule load julia\nsrun=\"srun -N 1\"\nparallel=\"parallel --delay 1 -j 128\"\n\n# run parallel jobs\n$srun  $parallel \"julia sensitivity.jl -c config_fake_data.json -i {1}\" ::: {1..10000} &\n\nwait","category":"page"},{"location":".ipynb_checkpoints/config-checkpoint/#Building-the-configuration-file","page":"Building the configuration file","title":"Building the configuration file","text":"","category":"section"},{"location":".ipynb_checkpoints/config-checkpoint/","page":"Building the configuration file","title":"Building the configuration file","text":"Before running the code, set the input config.json file with following entries:","category":"page"},{"location":".ipynb_checkpoints/config-checkpoint/","page":"Building the configuration file","title":"Building the configuration file","text":"{\n    \"debug\":false,\n    \"partitions\":[\"config/partitions_gerda_new.json\",\"config/partitions_l200.json\",\"config/partitions_mjd_new.json\"],\n    \"events\":    [\"config/events_gerda.json\",\"config/events_l200.json\",\"config/events_mjd_new_part.json\"],\n    \"output_path\": \"output/fit_mjd_l200_gerda_v2/\",\n    \"overwrite\":true,\n    \"bat_fit\": {\"nsteps\": 1e6, \"nchains\": 6},\n    \"plot\": {\n            \"fit_and_data\": false,\n            \"bandfit_and_data\": false,\n            \"scheme\":\"red\",\n            \"alpha\":0.3\n        },\n    \"bkg_only\": false,\n    \"signal\": {\"upper_bound\":1000, \"prior\": \"uniform\"},\n    \"bkg\": {\"upper_bound\":0.1,\n             \"prior\": \"uniform\"\n             },\n\n    ...\n}","category":"page"},{"location":".ipynb_checkpoints/config-checkpoint/","page":"Building the configuration file","title":"Building the configuration file","text":"where","category":"page"},{"location":".ipynb_checkpoints/config-checkpoint/","page":"Building the configuration file","title":"Building the configuration file","text":"\"debug\": true if you want to display debug output on terminal;\n\"partitions\": list of partitions JSON inputs; it takes one entry per experiment;\n\"events\": list of events JSON inputs; it takes one entry per experiment;\n\"output_path\": path where to store outputs (logs, plots, mcmc results);\n\"overwrite\": true if you want to overwrite a previous fit with same output_path; if set to false but no fits were previously performed (ie there are no outputs to overwrite), the code will save the output of this fit;\n\"bat_fit\": settings for the BAT fit;\n\"plot\": settings for plotting; \"fit_and_data\": true plots fit line over data (and CI bands if \"bandfit_and_data\": true); \"scheme\":\"red\" and \"alpha\":0.3 are used for customizing output appearances;\n\"bkg_only\": true if we fit assuming no signal (S=0), false otherwise;\n\"signal\": select \"upper_bound\" for the prior and the \"prior\" shape (uniform, sqrt, ...);\n\"bkg\": select \"upper_bound\" for the prior and the \"prior\" shape (uniform, ...) there are several optional keys with details given below, if these are not provided the fit defaults to a flat background without correlations.","category":"page"},{"location":".ipynb_checkpoints/config-checkpoint/","page":"Building the configuration file","title":"Building the configuration file","text":"Moreover, the config requires the following block for nuisance parameters, ie energy scale (=energy bias and resolution) and efficiency:","category":"page"},{"location":".ipynb_checkpoints/config-checkpoint/","page":"Building the configuration file","title":"Building the configuration file","text":"    {\n    ...\n    \"nuisance\": { \n        \"energy_scale\" : {\n            \"correlated\": true,\n            \"fixed\":     false\n            },\n         \"efficiency\" : {\n            \"correlated\": true,\n            \"fixed\": false\n            }\n    }","category":"page"},{"location":".ipynb_checkpoints/config-checkpoint/","page":"Building the configuration file","title":"Building the configuration file","text":"In particular, you can set \"correlated\": true if you want to use one variable to correlate the nuisance parameters (eg to speed up the computation times), and \"fixed\": false if you want to include a prior for nuisance parameters (otherwise these parameters they will be fixed to their partition value and not constrained).","category":"page"},{"location":".ipynb_checkpoints/config-checkpoint/","page":"Building the configuration file","title":"Building the configuration file","text":"If a variable is correlated (either energy_scale or efficency), the code will search for a field in the fit_groups block of the partitions JSON file to use a correlated variable per each fit group.  In particular, the field has to be specified as:","category":"page"},{"location":".ipynb_checkpoints/config-checkpoint/","page":"Building the configuration file","title":"Building the configuration file","text":"\"efficiency_group_name\": \"...\"\n\"energy_scale_group_name\": \"...\"","category":"page"},{"location":".ipynb_checkpoints/config-checkpoint/","page":"Building the configuration file","title":"Building the configuration file","text":"[!NOTE]  If the key doesn't exist, this defaults to \"all\"","category":"page"},{"location":".ipynb_checkpoints/config-checkpoint/","page":"Building the configuration file","title":"Building the configuration file","text":"Parameters are then added to the model called αr_$name (for resolution), αe_$name for efficiency and αb_$name for bias.","category":"page"},{"location":".ipynb_checkpoints/config-checkpoint/","page":"Building the configuration file","title":"Building the configuration file","text":"[!WARNING] The alpha parameter names default to _all, if you want one different per experiment this must be explicitly specified in the fit groups entry","category":"page"},{"location":".ipynb_checkpoints/config-checkpoint/#Background-shape-and-correlation","page":"Building the configuration file","title":"Background shape and correlation","text":"","category":"section"},{"location":".ipynb_checkpoints/config-checkpoint/","page":"Building the configuration file","title":"Building the configuration file","text":"There are several options to control the background in more detail. These can be added to the \"bkg\" section of the config: In particular:","category":"page"},{"location":".ipynb_checkpoints/config-checkpoint/","page":"Building the configuration file","title":"Building the configuration file","text":"\"correlated\" adds a hierachical (correlated) background to the model, this key should have a dictonary giving details on the prior shape and ranges for example:","category":"page"},{"location":".ipynb_checkpoints/config-checkpoint/","page":"Building the configuration file","title":"Building the configuration file","text":"\"correlated\":{\"mode\":\"lognormal\",\"range\":[0,0.1]}","category":"page"},{"location":".ipynb_checkpoints/config-checkpoint/","page":"Building the configuration file","title":"Building the configuration file","text":"The three options for the mode are 'lognormal', 'normal' or 'none'.While the range gives the range of the uniform prior on the \\sigma_B parameter.","category":"page"},{"location":".ipynb_checkpoints/config-checkpoint/","page":"Building the configuration file","title":"Building the configuration file","text":"\"shape\" changes the shape of the background from uniform. The user should provide a dictonary giving details on the shape:","category":"page"},{"location":".ipynb_checkpoints/config-checkpoint/","page":"Building the configuration file","title":"Building the configuration file","text":"for example:","category":"page"},{"location":".ipynb_checkpoints/config-checkpoint/","page":"Building the configuration file","title":"Building the configuration file","text":"\"shape\":{\n            \"name\":\"exponential\",\n            \"pars\":{\"slope\":[-10,10]}\n        },","category":"page"},{"location":".ipynb_checkpoints/config-checkpoint/","page":"Building the configuration file","title":"Building the configuration file","text":"The \"pars\" subdictonary describes the range of the priors on the parameters of the model, currently implemented shapes are \"uniform\", \"linear\" and \"exponential\". These names correspond to functions in fitting.jl and logical conditions in get_bkg_pdf in likelihood.jl.","category":"page"},{"location":".ipynb_checkpoints/config-checkpoint/","page":"Building the configuration file","title":"Building the configuration file","text":"This will add parameters ${bkg_name}_slope or similar to the model (and then call them). This names therefore must correspond to the names in the functions in fitting.jl. To add a new shape simply define a new method in fitting.jl and a new logical condition in get_bkg_pdf in likelihood.jl.","category":"page"},{"location":".ipynb_checkpoints/config-checkpoint/","page":"Building the configuration file","title":"Building the configuration file","text":"[!NOTE]  If these keys are not provided the model defaults to a uniform uncorrelated background.","category":"page"},{"location":".ipynb_checkpoints/index-checkpoint/#ZeroNuFit.jl-Documentation","page":"ZeroNuFit.jl Documentation","title":"ZeroNuFit.jl Documentation","text":"","category":"section"},{"location":".ipynb_checkpoints/index-checkpoint/","page":"ZeroNuFit.jl Documentation","title":"ZeroNuFit.jl Documentation","text":"Welcome to the documentation for ZeroNuFit.jl.","category":"page"},{"location":".ipynb_checkpoints/index-checkpoint/#Introduction","page":"ZeroNuFit.jl Documentation","title":"Introduction","text":"","category":"section"},{"location":".ipynb_checkpoints/index-checkpoint/","page":"ZeroNuFit.jl Documentation","title":"ZeroNuFit.jl Documentation","text":"ZeroNuFit.jl is a Julia package for running an unbinned fit of a gaussian signal over a background for the neutrinoless double beta decay analysis.","category":"page"},{"location":".ipynb_checkpoints/index-checkpoint/","page":"ZeroNuFit.jl Documentation","title":"ZeroNuFit.jl Documentation","text":"The tool is based on the BAT.jl package for performing a Bayesian analysis.","category":"page"},{"location":".ipynb_checkpoints/index-checkpoint/#Table-of-contents","page":"ZeroNuFit.jl Documentation","title":"Table of contents","text":"","category":"section"},{"location":".ipynb_checkpoints/index-checkpoint/","page":"ZeroNuFit.jl Documentation","title":"ZeroNuFit.jl Documentation","text":"Pages = [\n    \"installation.md\",\n    \"config.md\",\n    \"inputs.md\",\n    \"toys.md\"\n]\nDepth = 1","category":"page"},{"location":"installation/#First-steps","page":"First steps","title":"First steps","text":"","category":"section"},{"location":"installation/#How-to-run-the-code","page":"First steps","title":"How to run the code","text":"","category":"section"},{"location":"installation/","page":"First steps","title":"First steps","text":"Run the following command by specifying the path to the configuration file used for settings:","category":"page"},{"location":"installation/","page":"First steps","title":"First steps","text":"julia main.jl -c config/config.json","category":"page"},{"location":"installation/#Julia-Project-enviroments","page":"First steps","title":"Julia Project enviroments","text":"","category":"section"},{"location":"installation/","page":"First steps","title":"First steps","text":"To run the code in a virtual enviroment you can use the following.","category":"page"},{"location":"installation/","page":"First steps","title":"First steps","text":"julia\n] \nactivate .\ninstantiate\n","category":"page"},{"location":"installation/","page":"First steps","title":"First steps","text":"Now you can run the script inside this enviroment with:","category":"page"},{"location":"installation/","page":"First steps","title":"First steps","text":"julia main.jl --project=. -c config/config.json","category":"page"},{"location":"installation/","page":"First steps","title":"First steps","text":"[!NOTE]  The tool was developed for the LEGEND experiment. People from the LEGEND Collaborations can alternatively run the code within a LEGEND container with julia installed, see this tutorial for more details.","category":"page"},{"location":"installation/","page":"First steps","title":"First steps","text":"","category":"page"},{"location":".ipynb_checkpoints/inputs-checkpoint/#Partition-and-events-files","page":"Partition and events files","title":"Partition and events files","text":"","category":"section"},{"location":".ipynb_checkpoints/inputs-checkpoint/","page":"Partition and events files","title":"Partition and events files","text":"The takes inputs in JSON format, two files are needed a \"partitions file\" giving information on the independent spectra to be used in the fit/likelihood, this is set by the \"partitions\" key in the config file. This provides all the information neccesary to define the fit model.","category":"page"},{"location":".ipynb_checkpoints/inputs-checkpoint/","page":"Partition and events files","title":"Partition and events files","text":"The file consists of a file of independent spectra to include in the fit (for example channels or partitions). A partition is defined uniquely by a range of time-stamps, a detector name and an experiment name. ","category":"page"},{"location":".ipynb_checkpoints/inputs-checkpoint/","page":"Partition and events files","title":"Partition and events files","text":"[!NOTE] In principle the 'detector' does not need to be a single detector but can be a label for any groups of detectors. This allows to make fits where all detectors are fit together.","category":"page"},{"location":".ipynb_checkpoints/inputs-checkpoint/","page":"Partition and events files","title":"Partition and events files","text":"The partitions are grouped into fit_groups these are sets of partitions which are treated with the same background fit model and range. In the partitions file the user must provide the information on the fit groups and partitions, (organised by fit group). This file must be provided as a JSON file, this allows a full customisation of the fit.","category":"page"},{"location":".ipynb_checkpoints/inputs-checkpoint/","page":"Partition and events files","title":"Partition and events files","text":"This JSON file has a nested structure with two subdictonaries, the first with key \"fit_groups\", describing the groupings in the fit, and the second \"partitions\" giving a list of partitions for each fit group. An example is shown below.","category":"page"},{"location":".ipynb_checkpoints/inputs-checkpoint/","page":"Partition and events files","title":"Partition and events files","text":"{\n\"fit_groups\":{\n                \"group_one\":{\n                            \"range\":[[1930,2099],[2109,2114],[2124,2190]],\n                            \"model\":\"uniform\",\n                            \"bkg_name\":\"low_bkg\"\n                            }\n\n},\n\"partitions\": {\n                \"group_one\":[\n\n                            {  \n                                \"experiment\": \"LEGEND\",\n                                \"detector\": \"DET_0\",\n                                \"start_ts\": 1704950367,\n                                \"end_ts\": 1708271505,\n                                \"eff_tot\": 0.6,\n                                \"eff_tot_sigma\": 0.1,\n                                \"fwhm\": 3,\n                                \"fwhm_sigma\": 1,\n                                \"exposure\": 1,\n                                \"bias\": 0.2,\n                                \"bias_sigma\": 0.1\n                            }, ...\n                            ],\n                \"group_two\":...\n            },\n\n\n}\n            ","category":"page"},{"location":".ipynb_checkpoints/inputs-checkpoint/","page":"Partition and events files","title":"Partition and events files","text":"in future we will also add the possibility to customize further the fit. Currently it implements a fit to the energy spectrum with a uniform background. They key bkg_name is used to set the name of the background parameter for this group, note that several groups can be fitted with the same background parameter, this enables quick modifcation of the fit.","category":"page"},{"location":".ipynb_checkpoints/inputs-checkpoint/","page":"Partition and events files","title":"Partition and events files","text":"In addition, it is neccesary to provide an 'event' file describing the events observed in the data, the path to this file is specified by the 'events' key in the config. Again this is a JSON file consisting of a list of observed events of the form.","category":"page"},{"location":".ipynb_checkpoints/inputs-checkpoint/","page":"Partition and events files","title":"Partition and events files","text":"    {       \"experiment\":\"LEGEND\",\n            \"energy\": 2069.420,\n            \"timestamp\": 1755109448,\n            \"detector\": \"DET_0\"\n        },","category":"page"},{"location":".ipynb_checkpoints/inputs-checkpoint/","page":"Partition and events files","title":"Partition and events files","text":"The timestamp and detector are used to extract which partition this event corresponds to. To convert to this format from the standard GERDA and LEGEND files, there are tools available in https://github.com/tdixon97/legend-0vbb-config.","category":"page"},{"location":".ipynb_checkpoints/inputs-checkpoint/","page":"Partition and events files","title":"Partition and events files","text":"It is possible to supply a list of partition and event files in this case the list of fit groups and events are concatenated.","category":"page"},{"location":".ipynb_checkpoints/inputs-checkpoint/","page":"Partition and events files","title":"Partition and events files","text":"[!WARNING]   If multiple files are provided fit_group must still be unique.","category":"page"},{"location":"inputs/#Partition-and-events-files","page":"Partition and events files","title":"Partition and events files","text":"","category":"section"},{"location":"inputs/","page":"Partition and events files","title":"Partition and events files","text":"The takes inputs in JSON format, two files are needed a \"partitions file\" giving information on the independent spectra to be used in the fit/likelihood, this is set by the \"partitions\" key in the config file. This provides all the information neccesary to define the fit model.","category":"page"},{"location":"inputs/","page":"Partition and events files","title":"Partition and events files","text":"The file consists of a file of independent spectra to include in the fit (for example channels or partitions). A partition is defined uniquely by a range of time-stamps, a detector name and an experiment name. ","category":"page"},{"location":"inputs/","page":"Partition and events files","title":"Partition and events files","text":"[!NOTE] In principle the 'detector' does not need to be a single detector but can be a label for any groups of detectors. This allows to make fits where all detectors are fit together.","category":"page"},{"location":"inputs/","page":"Partition and events files","title":"Partition and events files","text":"The partitions are grouped into fit_groups these are sets of partitions which are treated with the same background fit model and range. In the partitions file the user must provide the information on the fit groups and partitions, (organised by fit group). This file must be provided as a JSON file, this allows a full customisation of the fit.","category":"page"},{"location":"inputs/","page":"Partition and events files","title":"Partition and events files","text":"This JSON file has a nested structure with two subdictonaries, the first with key \"fit_groups\", describing the groupings in the fit, and the second \"partitions\" giving a list of partitions for each fit group. An example is shown below.","category":"page"},{"location":"inputs/","page":"Partition and events files","title":"Partition and events files","text":"{\n\"fit_groups\":{\n                \"group_one\":{\n                            \"range\":[[1930,2099],[2109,2114],[2124,2190]],\n                            \"model\":\"uniform\",\n                            \"bkg_name\":\"low_bkg\"\n                            }\n\n},\n\"partitions\": {\n                \"group_one\":[\n\n                            {  \n                                \"experiment\": \"LEGEND\",\n                                \"detector\": \"DET_0\",\n                                \"start_ts\": 1704950367,\n                                \"end_ts\": 1708271505,\n                                \"eff_tot\": 0.6,\n                                \"eff_tot_sigma\": 0.1,\n                                \"fwhm\": 3,\n                                \"fwhm_sigma\": 1,\n                                \"exposure\": 1,\n                                \"bias\": 0.2,\n                                \"bias_sigma\": 0.1\n                            }, ...\n                            ],\n                \"group_two\":...\n            },\n\n\n}\n            ","category":"page"},{"location":"inputs/","page":"Partition and events files","title":"Partition and events files","text":"in future we will also add the possibility to customize further the fit. Currently it implements a fit to the energy spectrum with a uniform background. They key bkg_name is used to set the name of the background parameter for this group, note that several groups can be fitted with the same background parameter, this enables quick modifcation of the fit.","category":"page"},{"location":"inputs/","page":"Partition and events files","title":"Partition and events files","text":"In addition, it is neccesary to provide an 'event' file describing the events observed in the data, the path to this file is specified by the 'events' key in the config. Again this is a JSON file consisting of a list of observed events of the form.","category":"page"},{"location":"inputs/","page":"Partition and events files","title":"Partition and events files","text":"    {       \"experiment\":\"LEGEND\",\n            \"energy\": 2069.420,\n            \"timestamp\": 1755109448,\n            \"detector\": \"DET_0\"\n        },","category":"page"},{"location":"inputs/","page":"Partition and events files","title":"Partition and events files","text":"The timestamp and detector are used to extract which partition this event corresponds to. To convert to this format from the standard GERDA and LEGEND files, there are tools available in https://github.com/tdixon97/legend-0vbb-config.","category":"page"},{"location":"inputs/","page":"Partition and events files","title":"Partition and events files","text":"It is possible to supply a list of partition and event files in this case the list of fit groups and events are concatenated.","category":"page"},{"location":"inputs/","page":"Partition and events files","title":"Partition and events files","text":"[!WARNING]   If multiple files are provided fit_group must still be unique.","category":"page"},{"location":"#ZeroNuFit.jl-Documentation","page":"Home","title":"ZeroNuFit.jl Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Welcome to the documentation for ZeroNuFit.jl.","category":"page"},{"location":"#Introduction","page":"Home","title":"Introduction","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"ZeroNuFit.jl is a Julia package for running an unbinned fit of a gaussian signal over a background for the neutrinoless double beta decay analysis.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The tool is based on the BAT.jl package for performing a Bayesian analysis.","category":"page"},{"location":"#Table-of-contents","page":"Home","title":"Table of contents","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = [\n    \"installation.md\",\n    \"config.md\",\n    \"inputs.md\",\n    \"toys.md\"\n]\nDepth = 1","category":"page"},{"location":"config/#Building-the-configuration-file","page":"Building the configuration file","title":"Building the configuration file","text":"","category":"section"},{"location":"config/","page":"Building the configuration file","title":"Building the configuration file","text":"Before running the code, set the input config.json file with following entries:","category":"page"},{"location":"config/","page":"Building the configuration file","title":"Building the configuration file","text":"{\n    \"debug\":false,\n    \"partitions\":[\"config/partitions_gerda_new.json\",\"config/partitions_l200.json\",\"config/partitions_mjd_new.json\"],\n    \"events\":    [\"config/events_gerda.json\",\"config/events_l200.json\",\"config/events_mjd_new_part.json\"],\n    \"output_path\": \"output/fit_mjd_l200_gerda_v2/\",\n    \"overwrite\":true,\n    \"bat_fit\": {\"nsteps\": 1e6, \"nchains\": 6},\n    \"plot\": {\n            \"fit_and_data\": false,\n            \"bandfit_and_data\": false,\n            \"scheme\":\"red\",\n            \"alpha\":0.3\n        },\n    \"bkg_only\": false,\n    \"signal\": {\"upper_bound\":1000, \"prior\": \"uniform\"},\n    \"bkg\": {\"upper_bound\":0.1,\n             \"prior\": \"uniform\"\n             },\n\n    ...\n}","category":"page"},{"location":"config/","page":"Building the configuration file","title":"Building the configuration file","text":"where","category":"page"},{"location":"config/","page":"Building the configuration file","title":"Building the configuration file","text":"\"debug\": true if you want to display debug output on terminal;\n\"partitions\": list of partitions JSON inputs; it takes one entry per experiment;\n\"events\": list of events JSON inputs; it takes one entry per experiment;\n\"output_path\": path where to store outputs (logs, plots, mcmc results);\n\"overwrite\": true if you want to overwrite a previous fit with same output_path; if set to false but no fits were previously performed (ie there are no outputs to overwrite), the code will save the output of this fit;\n\"bat_fit\": settings for the BAT fit;\n\"plot\": settings for plotting; \"fit_and_data\": true plots fit line over data (and CI bands if \"bandfit_and_data\": true); \"scheme\":\"red\" and \"alpha\":0.3 are used for customizing output appearances;\n\"bkg_only\": true if we fit assuming no signal (S=0), false otherwise;\n\"signal\": select \"upper_bound\" for the prior and the \"prior\" shape (uniform, sqrt, ...);\n\"bkg\": select \"upper_bound\" for the prior and the \"prior\" shape (uniform, ...) there are several optional keys with details given below, if these are not provided the fit defaults to a flat background without correlations.","category":"page"},{"location":"config/","page":"Building the configuration file","title":"Building the configuration file","text":"Moreover, the config requires the following block for nuisance parameters, ie energy scale (=energy bias and resolution) and efficiency:","category":"page"},{"location":"config/","page":"Building the configuration file","title":"Building the configuration file","text":"    {\n    ...\n    \"nuisance\": { \n        \"energy_scale\" : {\n            \"correlated\": true,\n            \"fixed\":     false\n            },\n         \"efficiency\" : {\n            \"correlated\": true,\n            \"fixed\": false\n            }\n    }","category":"page"},{"location":"config/","page":"Building the configuration file","title":"Building the configuration file","text":"In particular, you can set \"correlated\": true if you want to use one variable to correlate the nuisance parameters (eg to speed up the computation times), and \"fixed\": false if you want to include a prior for nuisance parameters (otherwise these parameters they will be fixed to their partition value and not constrained).","category":"page"},{"location":"config/","page":"Building the configuration file","title":"Building the configuration file","text":"If a variable is correlated (either energy_scale or efficency), the code will search for a field in the fit_groups block of the partitions JSON file to use a correlated variable per each fit group.  In particular, the field has to be specified as:","category":"page"},{"location":"config/","page":"Building the configuration file","title":"Building the configuration file","text":"\"efficiency_group_name\": \"...\"\n\"energy_scale_group_name\": \"...\"","category":"page"},{"location":"config/","page":"Building the configuration file","title":"Building the configuration file","text":"[!NOTE]  If the key doesn't exist, this defaults to \"all\"","category":"page"},{"location":"config/","page":"Building the configuration file","title":"Building the configuration file","text":"Parameters are then added to the model called αr_$name (for resolution), αe_$name for efficiency and αb_$name for bias.","category":"page"},{"location":"config/","page":"Building the configuration file","title":"Building the configuration file","text":"[!WARNING] The alpha parameter names default to _all, if you want one different per experiment this must be explicitly specified in the fit groups entry","category":"page"},{"location":"config/#Background-shape-and-correlation","page":"Building the configuration file","title":"Background shape and correlation","text":"","category":"section"},{"location":"config/","page":"Building the configuration file","title":"Building the configuration file","text":"There are several options to control the background in more detail. These can be added to the \"bkg\" section of the config: In particular:","category":"page"},{"location":"config/","page":"Building the configuration file","title":"Building the configuration file","text":"\"correlated\" adds a hierachical (correlated) background to the model, this key should have a dictonary giving details on the prior shape and ranges for example:","category":"page"},{"location":"config/","page":"Building the configuration file","title":"Building the configuration file","text":"\"correlated\":{\"mode\":\"lognormal\",\"range\":[0,0.1]}","category":"page"},{"location":"config/","page":"Building the configuration file","title":"Building the configuration file","text":"The three options for the mode are 'lognormal', 'normal' or 'none'.While the range gives the range of the uniform prior on the \\sigma_B parameter.","category":"page"},{"location":"config/","page":"Building the configuration file","title":"Building the configuration file","text":"\"shape\" changes the shape of the background from uniform. The user should provide a dictonary giving details on the shape:","category":"page"},{"location":"config/","page":"Building the configuration file","title":"Building the configuration file","text":"for example:","category":"page"},{"location":"config/","page":"Building the configuration file","title":"Building the configuration file","text":"\"shape\":{\n            \"name\":\"exponential\",\n            \"pars\":{\"slope\":[-10,10]}\n        },","category":"page"},{"location":"config/","page":"Building the configuration file","title":"Building the configuration file","text":"The \"pars\" subdictonary describes the range of the priors on the parameters of the model, currently implemented shapes are \"uniform\", \"linear\" and \"exponential\". These names correspond to functions in fitting.jl and logical conditions in get_bkg_pdf in likelihood.jl.","category":"page"},{"location":"config/","page":"Building the configuration file","title":"Building the configuration file","text":"This will add parameters ${bkg_name}_slope or similar to the model (and then call them). This names therefore must correspond to the names in the functions in fitting.jl. To add a new shape simply define a new method in fitting.jl and a new logical condition in get_bkg_pdf in likelihood.jl.","category":"page"},{"location":"config/","page":"Building the configuration file","title":"Building the configuration file","text":"[!NOTE]  If these keys are not provided the model defaults to a uniform uncorrelated background.","category":"page"}]
}
